{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# reading raw data file\n",
    "data_train = pd.read_csv('Archivos_CSV_con_etiquetas/Medicion_manual_train_accelGyro_etiquetado.csv')\n",
    "data_train = data_train.drop(['gx','gy','gz'], axis=1)\n",
    "\n",
    "\n",
    "# reMovimientoing null values\n",
    "data_train = data_train.dropna()\n",
    "data_train.shape\n",
    "\n",
    "# drop the rows where timestamp is 0\n",
    "df = data_train[pd.to_datetime(data_train['dateTime_UTC']) != 0]\n",
    "\n",
    "# now arrange data in ascending order of the user and timestamp\n",
    "df = df.sort_values(by = ['dateTime_UTC'], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 114\n",
    "step_size = 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "ax1=sns.countplot(x = 'Actividades', data = df)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), fontsize=16)\n",
    "ax1.set_ylabel('Cuentas', fontsize=16)\n",
    "ax1.set_yticklabels(ax1.get_yticklabels(), fontsize=12)\n",
    "plt.xlabel('Actividades', fontsize=16)\n",
    "plt.title('Número de muestras para la medición de entenamiento',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafico series de los distintos movimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "for i in ['Quieto', 'Movimiento_1', 'Movimiento_2', 'Movimiento_3', 'Movimiento_4']:\n",
    "    data_ = df[(df['Actividades'] == i)][:50]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Crear las líneas con etiquetas\n",
    "    sns.lineplot(y='ax', x=pd.to_datetime(data_['dateTime_UTC']), data=data_, color='r', label='ax')\n",
    "    sns.lineplot(y='ay', x=pd.to_datetime(data_['dateTime_UTC']), data=data_, color='b', label='ay')\n",
    "    sns.lineplot(y='az', x=pd.to_datetime(data_['dateTime_UTC']), data=data_, color='y', label='az')\n",
    "\n",
    "    # Añadir leyenda automáticamente\n",
    "    plt.legend(fontsize=15)\n",
    "\n",
    "    # Etiquetas y título\n",
    "    plt.ylabel('Aceleración [$m/s^2$]', fontsize=20)\n",
    "    plt.xlabel('Tiempo [$s$]', fontsize=20)\n",
    "    plt.title(i, fontsize=20)\n",
    "    \n",
    "\n",
    "    # Mostrar gráfica\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distrubución de valores de aceleración en x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x21749f5d490>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.FacetGrid(df, hue = 'Actividades').map(sns.distplot, 'ax').add_legend()\n",
    "sns.FacetGrid(df, hue = 'Actividades').map(sns.distplot, 'ay').add_legend()\n",
    "sns.FacetGrid(df, hue = 'Actividades').map(sns.distplot, 'az').add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list_train = []\n",
    "y_list_train = []\n",
    "z_list_train = []\n",
    "train_labels = []\n",
    "\n",
    "# creating overlaping windows of size window-size\n",
    "for i in range(0, df_train.shape[0] - window_size, step_size):\n",
    "    xs = df_train['ax'].values[i: i + window_size]\n",
    "    ys = df_train['ay'].values[i: i + window_size]\n",
    "    zs = df_train['az'].values[i: i + window_size]\n",
    "    label = stats.mode(df_train['Actividades'][i: i + window_size])[0][0]\n",
    "\n",
    "    x_list_train.append(xs)\n",
    "    y_list_train.append(ys)\n",
    "    z_list_train.append(zs)\n",
    "    train_labels.append(label)\n",
    "\n",
    "# Statistical Features on raw x, y and z in time domain\n",
    "X_train = pd.DataFrame()\n",
    "\n",
    "# mean\n",
    "X_train['x_mean'] = pd.Series(x_list_train).apply(lambda x: x.mean())\n",
    "X_train['y_mean'] = pd.Series(y_list_train).apply(lambda x: x.mean())\n",
    "X_train['z_mean'] = pd.Series(z_list_train).apply(lambda x: x.mean())\n",
    "\n",
    "# std dev\n",
    "X_train['x_std'] = pd.Series(x_list_train).apply(lambda x: x.std())\n",
    "X_train['y_std'] = pd.Series(y_list_train).apply(lambda x: x.std())\n",
    "X_train['z_std'] = pd.Series(z_list_train).apply(lambda x: x.std())\n",
    "\n",
    "# avg absolute diff\n",
    "X_train['x_aad'] = pd.Series(x_list_train).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "X_train['y_aad'] = pd.Series(y_list_train).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "X_train['z_aad'] = pd.Series(z_list_train).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "\n",
    "# min\n",
    "X_train['x_min'] = pd.Series(x_list_train).apply(lambda x: x.min())\n",
    "X_train['y_min'] = pd.Series(y_list_train).apply(lambda x: x.min())\n",
    "X_train['z_min'] = pd.Series(z_list_train).apply(lambda x: x.min())\n",
    "\n",
    "# max\n",
    "X_train['x_max'] = pd.Series(x_list_train).apply(lambda x: x.max())\n",
    "X_train['y_max'] = pd.Series(y_list_train).apply(lambda x: x.max())\n",
    "X_train['z_max'] = pd.Series(z_list_train).apply(lambda x: x.max())\n",
    "\n",
    "# # max-min diff\n",
    "# X_train['x_maxmin_diff'] = X_train['x_max'] - X_train['x_min']\n",
    "# X_train['y_maxmin_diff'] = X_train['y_max'] - X_train['y_min']\n",
    "# X_train['z_maxmin_diff'] = X_train['z_max'] - X_train['z_min']\n",
    "\n",
    "# median\n",
    "X_train['x_median'] = pd.Series(x_list_train).apply(lambda x: np.median(x))\n",
    "X_train['y_median'] = pd.Series(y_list_train).apply(lambda x: np.median(x))\n",
    "X_train['z_median'] = pd.Series(z_list_train).apply(lambda x: np.median(x))\n",
    "\n",
    "# median abs dev \n",
    "X_train['x_mad'] = pd.Series(x_list_train).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "X_train['y_mad'] = pd.Series(y_list_train).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "X_train['z_mad'] = pd.Series(z_list_train).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "\n",
    "# interquartile range\n",
    "X_train['x_IQR'] = pd.Series(x_list_train).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "X_train['y_IQR'] = pd.Series(y_list_train).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "X_train['z_IQR'] = pd.Series(z_list_train).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "\n",
    "# negtive count\n",
    "X_train['x_neg_count'] = pd.Series(x_list_train).apply(lambda x: np.sum(x < 0))\n",
    "X_train['y_neg_count'] = pd.Series(y_list_train).apply(lambda x: np.sum(x < 0))\n",
    "X_train['z_neg_count'] = pd.Series(z_list_train).apply(lambda x: np.sum(x < 0))\n",
    "\n",
    "# positive count\n",
    "X_train['x_pos_count'] = pd.Series(x_list_train).apply(lambda x: np.sum(x > 0))\n",
    "X_train['y_pos_count'] = pd.Series(y_list_train).apply(lambda x: np.sum(x > 0))\n",
    "X_train['z_pos_count'] = pd.Series(z_list_train).apply(lambda x: np.sum(x > 0))\n",
    "\n",
    "# values above mean\n",
    "X_train['x_above_mean'] = pd.Series(x_list_train).apply(lambda x: np.sum(x > x.mean()))\n",
    "X_train['y_above_mean'] = pd.Series(y_list_train).apply(lambda x: np.sum(x > x.mean()))\n",
    "X_train['z_above_mean'] = pd.Series(z_list_train).apply(lambda x: np.sum(x > x.mean()))\n",
    "\n",
    "# number of peaks\n",
    "X_train['x_peak_count'] = pd.Series(x_list_train).apply(lambda x: len(find_peaks(x)[0]))\n",
    "X_train['y_peak_count'] = pd.Series(y_list_train).apply(lambda x: len(find_peaks(x)[0]))\n",
    "X_train['z_peak_count'] = pd.Series(z_list_train).apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "# # skewness\n",
    "# X_train['x_skewness'] = pd.Series(x_list_train).apply(lambda x: stats.skew(x))\n",
    "# X_train['y_skewness'] = pd.Series(y_list_train).apply(lambda x: stats.skew(x))\n",
    "# X_train['z_skewness'] = pd.Series(z_list_train).apply(lambda x: stats.skew(x))\n",
    "\n",
    "# # kurtosis\n",
    "# X_train['x_kurtosis'] = pd.Series(x_list_train).apply(lambda x: stats.kurtosis(x))\n",
    "# X_train['y_kurtosis'] = pd.Series(y_list_train).apply(lambda x: stats.kurtosis(x))\n",
    "# X_train['z_kurtosis'] = pd.Series(z_list_train).apply(lambda x: stats.kurtosis(x))\n",
    "\n",
    "# energy\n",
    "X_train['x_energy'] = pd.Series(x_list_train).apply(lambda x: np.sum(x**2)/window_size)\n",
    "X_train['y_energy'] = pd.Series(y_list_train).apply(lambda x: np.sum(x**2)/window_size)\n",
    "X_train['z_energy'] = pd.Series(z_list_train).apply(lambda x: np.sum(x**2)/window_size)\n",
    "\n",
    "# avg resultant\n",
    "X_train['avg_result_accl'] = [i.mean() for i in ((pd.Series(x_list_train)**2 + pd.Series(y_list_train)**2 + pd.Series(z_list_train)**2)**0.5)]\n",
    "\n",
    "# signal magnitude area\n",
    "X_train['sma'] =    pd.Series(x_list_train).apply(lambda x: np.sum(abs(x)/window_size)) + pd.Series(y_list_train).apply(lambda x: np.sum(abs(x)/window_size)) \\\n",
    "                  + pd.Series(z_list_train).apply(lambda x: np.sum(abs(x)/window_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # converting the signals from time domain to frequency domain using FFT\n",
    "# x_list_fft_train = pd.Series(x_list_train).apply(lambda x: np.abs(np.fft.fft(x))[1:step_size])\n",
    "# y_list_fft_train = pd.Series(y_list_train).apply(lambda x: np.abs(np.fft.fft(x))[1:step_size])\n",
    "# z_list_fft_train = pd.Series(z_list_train).apply(lambda x: np.abs(np.fft.fft(x))[1:step_size])\n",
    "\n",
    "# # Statistical Features on raw x, y and z in frequency domain\n",
    "# # FFT mean\n",
    "# X_train['x_mean_fft'] = pd.Series(x_list_fft_train).apply(lambda x: x.mean())\n",
    "# X_train['y_mean_fft'] = pd.Series(y_list_fft_train).apply(lambda x: x.mean())\n",
    "# X_train['z_mean_fft'] = pd.Series(z_list_fft_train).apply(lambda x: x.mean())\n",
    "\n",
    "# # FFT std dev\n",
    "# X_train['x_std_fft'] = pd.Series(x_list_fft_train).apply(lambda x: x.std())\n",
    "# X_train['y_std_fft'] = pd.Series(y_list_fft_train).apply(lambda x: x.std())\n",
    "# X_train['z_std_fft'] = pd.Series(z_list_fft_train).apply(lambda x: x.std())\n",
    "\n",
    "# # FFT avg absolute diff\n",
    "# X_train['x_aad_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "# X_train['y_aad_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "# X_train['z_aad_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "\n",
    "# # FFT min\n",
    "# X_train['x_min_fft'] = pd.Series(x_list_fft_train).apply(lambda x: x.min())\n",
    "# X_train['y_min_fft'] = pd.Series(y_list_fft_train).apply(lambda x: x.min())\n",
    "# X_train['z_min_fft'] = pd.Series(z_list_fft_train).apply(lambda x: x.min())\n",
    "\n",
    "# # FFT max\n",
    "# X_train['x_max_fft'] = pd.Series(x_list_fft_train).apply(lambda x: x.max())\n",
    "# X_train['y_max_fft'] = pd.Series(y_list_fft_train).apply(lambda x: x.max())\n",
    "# X_train['z_max_fft'] = pd.Series(z_list_fft_train).apply(lambda x: x.max())\n",
    "\n",
    "# # FFT max-min diff\n",
    "# X_train['x_maxmin_diff_fft'] = X_train['x_max_fft'] - X_train['x_min_fft']\n",
    "# X_train['y_maxmin_diff_fft'] = X_train['y_max_fft'] - X_train['y_min_fft']\n",
    "# X_train['z_maxmin_diff_fft'] = X_train['z_max_fft'] - X_train['z_min_fft']\n",
    "\n",
    "# # FFT median\n",
    "# X_train['x_median_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.median(x))\n",
    "# X_train['y_median_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.median(x))\n",
    "# X_train['z_median_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.median(x))\n",
    "\n",
    "# # FFT median abs dev \n",
    "# X_train['x_mad_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "# X_train['y_mad_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "# X_train['z_mad_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "\n",
    "# # FFT Interquartile range\n",
    "# X_train['x_IQR_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "# X_train['y_IQR_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "# X_train['z_IQR_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "\n",
    "# # FFT values above mean\n",
    "# X_train['x_above_mean_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.sum(x > x.mean()))\n",
    "# X_train['y_above_mean_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.sum(x > x.mean()))\n",
    "# X_train['z_above_mean_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.sum(x > x.mean()))\n",
    "\n",
    "# # FFT number of peaks\n",
    "# X_train['x_peak_count_fft'] = pd.Series(x_list_fft_train).apply(lambda x: len(find_peaks(x)[0]))\n",
    "# X_train['y_peak_count_fft'] = pd.Series(y_list_fft_train).apply(lambda x: len(find_peaks(x)[0]))\n",
    "# X_train['z_peak_count_fft'] = pd.Series(z_list_fft_train).apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "# # FFT skewness\n",
    "# X_train['x_skewness_fft'] = pd.Series(x_list_fft_train).apply(lambda x: stats.skew(x))\n",
    "# X_train['y_skewness_fft'] = pd.Series(y_list_fft_train).apply(lambda x: stats.skew(x))\n",
    "# X_train['z_skewness_fft'] = pd.Series(z_list_fft_train).apply(lambda x: stats.skew(x))\n",
    "\n",
    "# # FFT kurtosis\n",
    "# X_train['x_kurtosis_fft'] = pd.Series(x_list_fft_train).apply(lambda x: stats.kurtosis(x))\n",
    "# X_train['y_kurtosis_fft'] = pd.Series(y_list_fft_train).apply(lambda x: stats.kurtosis(x))\n",
    "# X_train['z_kurtosis_fft'] = pd.Series(z_list_fft_train).apply(lambda x: stats.kurtosis(x))\n",
    "\n",
    "# # FFT energy\n",
    "# X_train['x_energy_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.sum(x**2)/50)\n",
    "# X_train['y_energy_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.sum(x**2)/50)\n",
    "# X_train['z_energy_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.sum(x**2/50))\n",
    "\n",
    "# # FFT avg resultant\n",
    "# X_train['avg_result_accl_fft'] = [i.mean() for i in ((pd.Series(x_list_fft_train)**2 + pd.Series(y_list_fft_train)**2 + pd.Series(z_list_fft_train)**2)**0.5)]\n",
    "\n",
    "# # FFT Signal magnitude area\n",
    "# X_train['sma_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.sum(abs(x)/50)) + pd.Series(y_list_fft_train).apply(lambda x: np.sum(abs(x)/50)) \\\n",
    "#                      + pd.Series(z_list_fft_train).apply(lambda x: np.sum(abs(x)/50))\n",
    "\n",
    "# # Max Indices and Min indices \n",
    "\n",
    "# # index of max value in time domain\n",
    "# X_train['x_argmax'] = pd.Series(x_list_train).apply(lambda x: np.argmax(x))\n",
    "# X_train['y_argmax'] = pd.Series(y_list_train).apply(lambda x: np.argmax(x))\n",
    "# X_train['z_argmax'] = pd.Series(z_list_train).apply(lambda x: np.argmax(x))\n",
    "\n",
    "# # index of min value in time domain\n",
    "# X_train['x_argmin'] = pd.Series(x_list_train).apply(lambda x: np.argmin(x))\n",
    "# X_train['y_argmin'] = pd.Series(y_list_train).apply(lambda x: np.argmin(x))\n",
    "# X_train['z_argmin'] = pd.Series(z_list_train).apply(lambda x: np.argmin(x))\n",
    "\n",
    "# # absolute difference between above indices\n",
    "# X_train['x_arg_diff'] = abs(X_train['x_argmax'] - X_train['x_argmin'])\n",
    "# X_train['y_arg_diff'] = abs(X_train['y_argmax'] - X_train['y_argmin'])\n",
    "# X_train['z_arg_diff'] = abs(X_train['z_argmax'] - X_train['z_argmin'])\n",
    "\n",
    "# # index of max value in frequency domain\n",
    "# X_train['x_argmax_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.argmax(np.abs(np.fft.fft(x))[1:51]))\n",
    "# X_train['y_argmax_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.argmax(np.abs(np.fft.fft(x))[1:51]))\n",
    "# X_train['z_argmax_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.argmax(np.abs(np.fft.fft(x))[1:51]))\n",
    "\n",
    "# # index of min value in frequency domain\n",
    "# X_train['x_argmin_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.argmin(np.abs(np.fft.fft(x))[1:51]))\n",
    "# X_train['y_argmin_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.argmin(np.abs(np.fft.fft(x))[1:51]))\n",
    "# X_train['z_argmin_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.argmin(np.abs(np.fft.fft(x))[1:51]))\n",
    "\n",
    "# # absolute difference between above indices\n",
    "# X_train['x_arg_diff_fft'] = abs(X_train['x_argmax_fft'] - X_train['x_argmin_fft'])\n",
    "# X_train['y_arg_diff_fft'] = abs(X_train['y_argmax_fft'] - X_train['y_argmin_fft'])\n",
    "# X_train['z_arg_diff_fft'] = abs(X_train['z_argmax_fft'] - X_train['z_argmin_fft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el vector de actividades en un DataFrame de pandas\n",
    "df = pd.DataFrame(train_labels, columns=['Actividad'])\n",
    "sns.set_style('whitegrid')\n",
    "# Crear el histograma utilizando sns.countplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='Actividad')\n",
    "plt.title('Frecuencia de actividades por ventana')\n",
    "plt.xlabel('Actividad')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genero X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading raw data file\n",
    "data_test = pd.read_csv('Archivos_CSV_con_etiquetas/Medicion_manual_test_accelGyro_etiquetado.csv')\n",
    "data_test = data_test.drop(['gx','gy','gz'], axis=1)\n",
    "\n",
    "\n",
    "# removing null values\n",
    "data_test = data_test.dropna()\n",
    "data_test.shape\n",
    "\n",
    "# drop the rows where timestamp is 0\n",
    "df_test = data_test[pd.to_datetime(data_test['dateTime_UTC']) != 0]\n",
    "\n",
    "# now arrange data in ascending order of the user and timestamp\n",
    "df_test = df_test.sort_values(by = ['dateTime_UTC'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize = (10, 5))\n",
    "sns.countplot(x = 'Actividades', data = df_test)\n",
    "plt.title('Número de muestras para la medición de prueba')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafico series de los distintos Movimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "for i in ['Quieto', 'Movimiento_1', 'Movimiento_2', 'Movimiento_3', 'Movimiento_4']:\n",
    "    data_ = df_test[(df_test['Actividades'] == i)][:50]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Crear las líneas con etiquetas\n",
    "    sns.lineplot(y='ax', x=pd.to_datetime(data_['dateTime_UTC']), data=data_, color='r', label='ax')\n",
    "    sns.lineplot(y='ay', x=pd.to_datetime(data_['dateTime_UTC']), data=data_, color='b', label='ay')\n",
    "    sns.lineplot(y='az', x=pd.to_datetime(data_['dateTime_UTC']), data=data_, color='y', label='az')\n",
    "\n",
    "    # Añadir leyenda automáticamente\n",
    "    plt.legend(fontsize=15)\n",
    "\n",
    "    # Etiquetas y título\n",
    "    plt.ylabel('Aceleración [$m/s^2$]', fontsize=20)\n",
    "    plt.xlabel('Tiempo [$s$]', fontsize=20)\n",
    "    plt.title(i, fontsize=20)\n",
    "    \n",
    "\n",
    "    # Mostrar gráfica\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distrubución de valores de aceleración en x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x21748436190>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.FacetGrid(df_test, hue = 'Actividades').map(sns.distplot, 'ax').add_legend()\n",
    "sns.FacetGrid(df_test, hue = 'Actividades').map(sns.distplot, 'ay').add_legend()\n",
    "sns.FacetGrid(df_test, hue = 'Actividades').map(sns.distplot, 'az').add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list_test = []\n",
    "y_list_test = []\n",
    "z_list_test = []\n",
    "test_labels = []\n",
    "\n",
    "\n",
    "\n",
    "# creating overlaping windows of size window-size\n",
    "for i in range(0, df_test.shape[0] - window_size, step_size):\n",
    "    xs = df_test['ax'].values[i: i + window_size]\n",
    "    ys = df_test['ay'].values[i: i + window_size]\n",
    "    zs = df_test['az'].values[i: i + window_size]\n",
    "    label = stats.mode(df_test['Actividades'][i: i + window_size])[0][0]\n",
    "\n",
    "    x_list_test.append(xs)\n",
    "    y_list_test.append(ys)\n",
    "    z_list_test.append(zs)\n",
    "    test_labels.append(label)\n",
    "\n",
    "# Statistical Features on raw x, y and z in time domain\n",
    "X_test = pd.DataFrame()\n",
    "\n",
    "# mean\n",
    "X_test['x_mean'] = pd.Series(x_list_test).apply(lambda x: x.mean())\n",
    "X_test['y_mean'] = pd.Series(y_list_test).apply(lambda x: x.mean())\n",
    "X_test['z_mean'] = pd.Series(z_list_test).apply(lambda x: x.mean())\n",
    "\n",
    "# std dev\n",
    "X_test['x_std'] = pd.Series(x_list_test).apply(lambda x: x.std())\n",
    "X_test['y_std'] = pd.Series(y_list_test).apply(lambda x: x.std())\n",
    "X_test['z_std'] = pd.Series(z_list_test).apply(lambda x: x.std())\n",
    "\n",
    "# avg absolute diff\n",
    "X_test['x_aad'] = pd.Series(x_list_test).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "X_test['y_aad'] = pd.Series(y_list_test).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "X_test['z_aad'] = pd.Series(z_list_test).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "\n",
    "# min\n",
    "X_test['x_min'] = pd.Series(x_list_test).apply(lambda x: x.min())\n",
    "X_test['y_min'] = pd.Series(y_list_test).apply(lambda x: x.min())\n",
    "X_test['z_min'] = pd.Series(z_list_test).apply(lambda x: x.min())\n",
    "\n",
    "# max\n",
    "X_test['x_max'] = pd.Series(x_list_test).apply(lambda x: x.max())\n",
    "X_test['y_max'] = pd.Series(y_list_test).apply(lambda x: x.max())\n",
    "X_test['z_max'] = pd.Series(z_list_test).apply(lambda x: x.max())\n",
    "\n",
    "# #max-min diff\n",
    "# X_test['x_maxmin_diff'] = X_test['x_max'] - X_test['x_min']\n",
    "# X_test['y_maxmin_diff'] = X_test['y_max'] - X_test['y_min']\n",
    "# X_test['z_maxmin_diff'] = X_test['z_max'] - X_test['z_min']\n",
    "\n",
    "# median\n",
    "X_test['x_median'] = pd.Series(x_list_test).apply(lambda x: np.median(x))\n",
    "X_test['y_median'] = pd.Series(y_list_test).apply(lambda x: np.median(x))\n",
    "X_test['z_median'] = pd.Series(z_list_test).apply(lambda x: np.median(x))\n",
    "\n",
    "# median abs dev \n",
    "X_test['x_mad'] = pd.Series(x_list_test).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "X_test['y_mad'] = pd.Series(y_list_test).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "X_test['z_mad'] = pd.Series(z_list_test).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "\n",
    "# interquartile range\n",
    "X_test['x_IQR'] = pd.Series(x_list_test).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "X_test['y_IQR'] = pd.Series(y_list_test).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "X_test['z_IQR'] = pd.Series(z_list_test).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "\n",
    "# negtive count\n",
    "X_test['x_neg_count'] = pd.Series(x_list_test).apply(lambda x: np.sum(x < 0))\n",
    "X_test['y_neg_count'] = pd.Series(y_list_test).apply(lambda x: np.sum(x < 0))\n",
    "X_test['z_neg_count'] = pd.Series(z_list_test).apply(lambda x: np.sum(x < 0))\n",
    "\n",
    "# positive count\n",
    "X_test['x_pos_count'] = pd.Series(x_list_test).apply(lambda x: np.sum(x > 0))\n",
    "X_test['y_pos_count'] = pd.Series(y_list_test).apply(lambda x: np.sum(x > 0))\n",
    "X_test['z_pos_count'] = pd.Series(z_list_test).apply(lambda x: np.sum(x > 0))\n",
    "\n",
    "# values above mean\n",
    "X_test['x_above_mean'] = pd.Series(x_list_test).apply(lambda x: np.sum(x > x.mean()))\n",
    "X_test['y_above_mean'] = pd.Series(y_list_test).apply(lambda x: np.sum(x > x.mean()))\n",
    "X_test['z_above_mean'] = pd.Series(z_list_test).apply(lambda x: np.sum(x > x.mean()))\n",
    "\n",
    "# number of peaks\n",
    "X_test['x_peak_count'] = pd.Series(x_list_test).apply(lambda x: len(find_peaks(x)[0]))\n",
    "X_test['y_peak_count'] = pd.Series(y_list_test).apply(lambda x: len(find_peaks(x)[0]))\n",
    "X_test['z_peak_count'] = pd.Series(z_list_test).apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "# # skewness\n",
    "# X_test['x_skewness'] = pd.Series(x_list_test).apply(lambda x: stats.skew(x))\n",
    "# X_test['y_skewness'] = pd.Series(y_list_test).apply(lambda x: stats.skew(x))\n",
    "# X_test['z_skewness'] = pd.Series(z_list_test).apply(lambda x: stats.skew(x))\n",
    "\n",
    "# # kurtosis\n",
    "# X_test['x_kurtosis'] = pd.Series(x_list_test).apply(lambda x: stats.kurtosis(x))\n",
    "# X_test['y_kurtosis'] = pd.Series(y_list_test).apply(lambda x: stats.kurtosis(x))\n",
    "# X_test['z_kurtosis'] = pd.Series(z_list_test).apply(lambda x: stats.kurtosis(x))\n",
    "\n",
    "# energy\n",
    "X_test['x_energy'] = pd.Series(x_list_test).apply(lambda x: np.sum(x**2)/window_size)\n",
    "X_test['y_energy'] = pd.Series(y_list_test).apply(lambda x: np.sum(x**2)/window_size)\n",
    "X_test['z_energy'] = pd.Series(z_list_test).apply(lambda x: np.sum(x**2)/window_size)\n",
    "\n",
    "# avg resultant\n",
    "X_test['avg_result_accl'] = [i.mean() for i in ((pd.Series(x_list_test)**2 + pd.Series(y_list_test)**2 + pd.Series(z_list_test)**2)**0.5)]\n",
    "\n",
    "# signal magnitude area\n",
    "X_test['sma'] =    pd.Series(x_list_test).apply(lambda x: np.sum(abs(x)/window_size)) + pd.Series(y_list_test).apply(lambda x: np.sum(abs(x)/window_size)) \\\n",
    "                  + pd.Series(z_list_test).apply(lambda x: np.sum(abs(x)/window_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # converting the signals from time domain to frequency domain using FFT\n",
    "# x_list_fft_test = pd.Series(x_list_test).apply(lambda x: np.abs(np.fft.fft(x))[1:step_size])\n",
    "# y_list_fft_test = pd.Series(y_list_test).apply(lambda x: np.abs(np.fft.fft(x))[1:step_size])\n",
    "# z_list_fft_test = pd.Series(z_list_test).apply(lambda x: np.abs(np.fft.fft(x))[1:step_size])\n",
    "\n",
    "# # Statistical Features on raw x, y and z in frequency domain\n",
    "# # FFT mean\n",
    "# X_test['x_mean_fft'] = pd.Series(x_list_fft_test).apply(lambda x: x.mean())\n",
    "# X_test['y_mean_fft'] = pd.Series(y_list_fft_test).apply(lambda x: x.mean())\n",
    "# X_test['z_mean_fft'] = pd.Series(z_list_fft_test).apply(lambda x: x.mean())\n",
    "\n",
    "# # FFT std dev\n",
    "# X_test['x_std_fft'] = pd.Series(x_list_fft_test).apply(lambda x: x.std())\n",
    "# X_test['y_std_fft'] = pd.Series(y_list_fft_test).apply(lambda x: x.std())\n",
    "# X_test['z_std_fft'] = pd.Series(z_list_fft_test).apply(lambda x: x.std())\n",
    "\n",
    "# # FFT avg absolute diff\n",
    "# X_test['x_aad_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "# X_test['y_aad_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "# X_test['z_aad_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "\n",
    "# # FFT min\n",
    "# X_test['x_min_fft'] = pd.Series(x_list_fft_test).apply(lambda x: x.min())\n",
    "# X_test['y_min_fft'] = pd.Series(y_list_fft_test).apply(lambda x: x.min())\n",
    "# X_test['z_min_fft'] = pd.Series(z_list_fft_test).apply(lambda x: x.min())\n",
    "\n",
    "# # FFT max\n",
    "# X_test['x_max_fft'] = pd.Series(x_list_fft_test).apply(lambda x: x.max())\n",
    "# X_test['y_max_fft'] = pd.Series(y_list_fft_test).apply(lambda x: x.max())\n",
    "# X_test['z_max_fft'] = pd.Series(z_list_fft_test).apply(lambda x: x.max())\n",
    "\n",
    "# # FFT max-min diff\n",
    "# X_test['x_maxmin_diff_fft'] = X_test['x_max_fft'] - X_test['x_min_fft']\n",
    "# X_test['y_maxmin_diff_fft'] = X_test['y_max_fft'] - X_test['y_min_fft']\n",
    "# X_test['z_maxmin_diff_fft'] = X_test['z_max_fft'] - X_test['z_min_fft']\n",
    "\n",
    "# # FFT median\n",
    "# X_test['x_median_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.median(x))\n",
    "# X_test['y_median_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.median(x))\n",
    "# X_test['z_median_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.median(x))\n",
    "\n",
    "# # FFT median abs dev \n",
    "# X_test['x_mad_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "# X_test['y_mad_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "# X_test['z_mad_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "\n",
    "# # FFT Interquartile range\n",
    "# X_test['x_IQR_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "# X_test['y_IQR_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "# X_test['z_IQR_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "\n",
    "# # FFT values above mean\n",
    "# X_test['x_above_mean_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.sum(x > x.mean()))\n",
    "# X_test['y_above_mean_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.sum(x > x.mean()))\n",
    "# X_test['z_above_mean_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.sum(x > x.mean()))\n",
    "\n",
    "# # FFT number of peaks\n",
    "# X_test['x_peak_count_fft'] = pd.Series(x_list_fft_test).apply(lambda x: len(find_peaks(x)[0]))\n",
    "# X_test['y_peak_count_fft'] = pd.Series(y_list_fft_test).apply(lambda x: len(find_peaks(x)[0]))\n",
    "# X_test['z_peak_count_fft'] = pd.Series(z_list_fft_test).apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "# # FFT skewness\n",
    "# X_test['x_skewness_fft'] = pd.Series(x_list_fft_test).apply(lambda x: stats.skew(x))\n",
    "# X_test['y_skewness_fft'] = pd.Series(y_list_fft_test).apply(lambda x: stats.skew(x))\n",
    "# X_test['z_skewness_fft'] = pd.Series(z_list_fft_test).apply(lambda x: stats.skew(x))\n",
    "\n",
    "# # FFT kurtosis\n",
    "# X_test['x_kurtosis_fft'] = pd.Series(x_list_fft_test).apply(lambda x: stats.kurtosis(x))\n",
    "# X_test['y_kurtosis_fft'] = pd.Series(y_list_fft_test).apply(lambda x: stats.kurtosis(x))\n",
    "# X_test['z_kurtosis_fft'] = pd.Series(z_list_fft_test).apply(lambda x: stats.kurtosis(x))\n",
    "\n",
    "# # FFT energy\n",
    "# X_test['x_energy_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.sum(x**2)/50)\n",
    "# X_test['y_energy_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.sum(x**2)/50)\n",
    "# X_test['z_energy_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.sum(x**2/50))\n",
    "\n",
    "# # FFT avg resultant\n",
    "# X_test['avg_result_accl_fft'] = [i.mean() for i in ((pd.Series(x_list_fft_test)**2 + pd.Series(y_list_fft_test)**2 + pd.Series(z_list_fft_test)**2)**0.5)]\n",
    "\n",
    "# # FFT Signal magnitude area\n",
    "# X_test['sma_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.sum(abs(x)/50)) + pd.Series(y_list_fft_test).apply(lambda x: np.sum(abs(x)/50)) \\\n",
    "#                      + pd.Series(z_list_fft_test).apply(lambda x: np.sum(abs(x)/50))\n",
    "\n",
    "# # Max Indices and Min indices \n",
    "\n",
    "# # index of max value in time domain\n",
    "# X_test['x_argmax'] = pd.Series(x_list_test).apply(lambda x: np.argmax(x))\n",
    "# X_test['y_argmax'] = pd.Series(y_list_test).apply(lambda x: np.argmax(x))\n",
    "# X_test['z_argmax'] = pd.Series(z_list_test).apply(lambda x: np.argmax(x))\n",
    "\n",
    "# # index of min value in time domain\n",
    "# X_test['x_argmin'] = pd.Series(x_list_test).apply(lambda x: np.argmin(x))\n",
    "# X_test['y_argmin'] = pd.Series(y_list_test).apply(lambda x: np.argmin(x))\n",
    "# X_test['z_argmin'] = pd.Series(z_list_test).apply(lambda x: np.argmin(x))\n",
    "\n",
    "# # absolute difference between above indices\n",
    "# X_test['x_arg_diff'] = abs(X_test['x_argmax'] - X_test['x_argmin'])\n",
    "# X_test['y_arg_diff'] = abs(X_test['y_argmax'] - X_test['y_argmin'])\n",
    "# X_test['z_arg_diff'] = abs(X_test['z_argmax'] - X_test['z_argmin'])\n",
    "\n",
    "# # index of max value in frequency domain\n",
    "# X_test['x_argmax_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.argmax(np.abs(np.fft.fft(x))[1:51]))\n",
    "# X_test['y_argmax_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.argmax(np.abs(np.fft.fft(x))[1:51]))\n",
    "# X_test['z_argmax_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.argmax(np.abs(np.fft.fft(x))[1:51]))\n",
    "\n",
    "# # index of min value in frequency domain\n",
    "# X_test['x_argmin_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.argmin(np.abs(np.fft.fft(x))[1:51]))\n",
    "# X_test['y_argmin_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.argmin(np.abs(np.fft.fft(x))[1:51]))\n",
    "# X_test['z_argmin_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.argmin(np.abs(np.fft.fft(x))[1:51]))\n",
    "\n",
    "# # absolute difference between above indices\n",
    "# X_test['x_arg_diff_fft'] = abs(X_test['x_argmax_fft'] - X_test['x_argmin_fft'])\n",
    "# X_test['y_arg_diff_fft'] = abs(X_test['y_argmax_fft'] - X_test['y_argmin_fft'])\n",
    "# X_test['z_arg_diff_fft'] = abs(X_test['z_argmax_fft'] - X_test['z_argmin_fft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el vector de actividades en un DataFrame de pandas\n",
    "df = pd.DataFrame(test_labels, columns=['Actividad'])\n",
    "sns.set_style('whitegrid')\n",
    "# Crear el histograma utilizando sns.countplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='Actividad')\n",
    "plt.title('Frecuencia de actividades por ventana')\n",
    "plt.xlabel('Actividad')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = np.array(train_labels)\n",
    "act_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9917355371900827\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Movimiento_1       1.00      1.00      1.00        26\n",
      "Movimiento_2       0.96      1.00      0.98        26\n",
      "Movimiento_3       1.00      1.00      1.00        22\n",
      "Movimiento_4       1.00      1.00      1.00        20\n",
      "      Quieto       1.00      0.96      0.98        27\n",
      "\n",
      "    accuracy                           0.99       121\n",
      "   macro avg       0.99      0.99      0.99       121\n",
      "weighted avg       0.99      0.99      0.99       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "# standardization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_data_lr = scaler.transform(X_train)\n",
    "X_test_data_lr = scaler.transform(X_test)\n",
    "# logistic regression model\n",
    "lr = LogisticRegression(random_state = 21)\n",
    "lr.fit(X_train_data_lr, act)\n",
    "act_pred = lr.predict(X_test_data_lr)\n",
    "print(\"Accuracy:\", accuracy_score(act_test, act_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(act_test,act_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la librería necesaria\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Supongamos que tienes definidas las variables act_test y act_pred\n",
    "\n",
    "# Generar la matriz de confusión\n",
    "confusion_matrix = confusion_matrix(act_test, act_pred)\n",
    "\n",
    "# Etiquetas de las clases\n",
    "labels = ['Quieto', 'Movimiento_1', 'Mov_2', 'Mov_3', 'Mov_4']\n",
    "\n",
    "# Crear figura y ejes\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(confusion_matrix, cmap='YlGnBu')  # Cambiar el colormap aquí\n",
    "\n",
    "# Mostrar todas las etiquetas de las clases\n",
    "ax.set_xticks(np.arange(len(labels)))\n",
    "ax.set_yticks(np.arange(len(labels)))\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "# Rotar las etiquetas para que sean legibles\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Mostrar los valores de cada celda\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(labels)):\n",
    "        text = ax.text(j, i, confusion_matrix[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "# Configuración del título y etiquetas de los ejes\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# Agregar la barra de referencia al lado\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "# Eliminar las líneas divisorias entre los cuadrados\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.tick_params(axis=u'both', which=u'both',length=0)\n",
    "ax.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo en X: 0.9917355371900827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Movimiento_1       1.00      1.00      1.00        26\n",
      "Movimiento_2       0.96      1.00      0.98        26\n",
      "Movimiento_3       1.00      1.00      1.00        22\n",
      "Movimiento_4       1.00      1.00      1.00        20\n",
      "      Quieto       1.00      0.96      0.98        27\n",
      "\n",
      "    accuracy                           0.99       121\n",
      "   macro avg       0.99      0.99      0.99       121\n",
      "weighted avg       0.99      0.99      0.99       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# standardization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_data_rf = scaler.transform(X_train)\n",
    "X_test_data_rf = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "#Entrenar el modelo\n",
    "modeloX = RandomForestClassifier()\n",
    "modeloX.fit(X_train_data_rf, act)\n",
    "\n",
    "#Evaluar el modelo\n",
    "act_pred_rf = modeloX.predict(X_test_data_rf)\n",
    "accuracyX = accuracy_score(act_test, act_pred)\n",
    "precision_recall_fscore = precision_recall_fscore_support(act_test,act_pred_rf,average=None)\n",
    "\n",
    "print(\"Accuracy del modelo en X:\", accuracyX)\n",
    "print(classification_report(act_test,act_pred))\n",
    "\n",
    "#Graficar precisionvsrecall\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Generar la matriz de confusión\n",
    "confusion_matrix = confusion_matrix(act_test, act_pred)\n",
    "\n",
    "# Etiquetas de las clases\n",
    "labels = ['Quieto', 'Movimiento_1', 'Mov_2', 'Mov_3', 'Movimiento_4']\n",
    "\n",
    "# Crear figura y ejes\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(confusion_matrix, cmap='YlGnBu')  # Cambiar el colormap aquí\n",
    "\n",
    "# Mostrar todas las etiquetas de las clases\n",
    "ax.set_xticks(np.arange(len(labels)))\n",
    "ax.set_yticks(np.arange(len(labels)))\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "# Rotar las etiquetas para que sean legibles\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Mostrar los valores de cada celda\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(labels)):\n",
    "        text = ax.text(j, i, confusion_matrix[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "# Configuración del título y etiquetas de los ejes\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# Agregar la barra de referencia al lado\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "# Eliminar las líneas divisorias entre los cuadrados\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.tick_params(axis=u'both', which=u'both',length=0)\n",
    "ax.grid(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
