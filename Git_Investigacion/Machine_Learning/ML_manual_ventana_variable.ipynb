{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%matplotlib qt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etiquetas de las clases\n",
    "labels = ['Quieto', 'Movimiento_1', 'Movimiento_2', 'Movimiento_3', 'Movimiento_4']\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "### TRAIN\n",
    "# reading raw data file\n",
    "data_train = pd.read_csv('Archivos_CSV_con_etiquetas/Medicion_manual_train_accelGyro_etiquetado.csv')\n",
    "data_train = data_train.drop(['gx','gy','gz'], axis=1)\n",
    "# removing null values\n",
    "data_train = data_train.dropna()\n",
    "data_train.shape\n",
    "# drop the rows where timestamp is 0\n",
    "df = data_train[pd.to_datetime(data_train['dateTime_UTC']) != 0]\n",
    "# now arrange data in ascending order of the user and timestamp\n",
    "df = df.sort_values(by = ['dateTime_UTC'], ignore_index=True)\n",
    "\n",
    "\n",
    "### TEST\n",
    "# reading raw data file\n",
    "data_test = pd.read_csv('Archivos_CSV_con_etiquetas/Medicion_manual_test_accelGyro_etiquetado.csv')\n",
    "data_test = data_test.drop(['gx','gy','gz'], axis=1)\n",
    "# removing null values\n",
    "data_test = data_test.dropna()\n",
    "data_test.shape\n",
    "# drop the rows where timestamp is 0\n",
    "df_test = data_test[pd.to_datetime(data_test['dateTime_UTC']) != 0]\n",
    "# now arrange data in ascending order of the user and timestamp\n",
    "df_test = df_test.sort_values(by = ['dateTime_UTC'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyX_lr = []\n",
    "accuracyX_rf = []\n",
    "precisionX_rf = []\n",
    "precisionX_lr = []\n",
    "recallX_lr = []\n",
    "recallX_rf = []\n",
    "fscoreX_lr = []\n",
    "fscoreX_rf = []\n",
    "windows = []\n",
    "\n",
    "for i in range(10):\n",
    "    #print(i)\n",
    "    step_size=1+56*i\n",
    "    \n",
    "    window_size=2*step_size\n",
    "    df_train = data_train\n",
    "    df_test=data_test\n",
    "    windows.append(window_size)\n",
    "\n",
    "\n",
    "    ### X TRAIN\n",
    "    x_list_train = []\n",
    "    y_list_train = []\n",
    "    z_list_train = []\n",
    "    train_labels = []\n",
    "\n",
    "    # creating overlaping windows of size window-size\n",
    "    for i in range(0, df_train.shape[0] - window_size, step_size):\n",
    "        xs = df_train['ax'].values[i: i + window_size]\n",
    "        ys = df_train['ay'].values[i: i + window_size]\n",
    "        zs = df_train['az'].values[i: i + window_size]\n",
    "        label = stats.mode(df_train['Actividades'][i: i + window_size])[0][0]\n",
    "\n",
    "        x_list_train.append(xs)\n",
    "        y_list_train.append(ys)\n",
    "        z_list_train.append(zs)\n",
    "        train_labels.append(label)\n",
    "\n",
    "    # Statistical Features on raw x, y and z in time domain\n",
    "    X_train = pd.DataFrame()\n",
    "\n",
    "    # mean\n",
    "    X_train['x_mean'] = pd.Series(x_list_train).apply(lambda x: x.mean())\n",
    "    X_train['y_mean'] = pd.Series(y_list_train).apply(lambda x: x.mean())\n",
    "    X_train['z_mean'] = pd.Series(z_list_train).apply(lambda x: x.mean())\n",
    "\n",
    "    # std dev\n",
    "    X_train['x_std'] = pd.Series(x_list_train).apply(lambda x: x.std())\n",
    "    X_train['y_std'] = pd.Series(y_list_train).apply(lambda x: x.std())\n",
    "    X_train['z_std'] = pd.Series(z_list_train).apply(lambda x: x.std())\n",
    "\n",
    "    # avg absolute diff\n",
    "    X_train['x_aad'] = pd.Series(x_list_train).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X_train['y_aad'] = pd.Series(y_list_train).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X_train['z_aad'] = pd.Series(z_list_train).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "\n",
    "    # min\n",
    "    X_train['x_min'] = pd.Series(x_list_train).apply(lambda x: x.min())\n",
    "    X_train['y_min'] = pd.Series(y_list_train).apply(lambda x: x.min())\n",
    "    X_train['z_min'] = pd.Series(z_list_train).apply(lambda x: x.min())\n",
    "\n",
    "    # max\n",
    "    X_train['x_max'] = pd.Series(x_list_train).apply(lambda x: x.max())\n",
    "    X_train['y_max'] = pd.Series(y_list_train).apply(lambda x: x.max())\n",
    "    X_train['z_max'] = pd.Series(z_list_train).apply(lambda x: x.max())\n",
    "\n",
    "    # # max-min diff\n",
    "    # X_train['x_maxmin_diff'] = X_train['x_max'] - X_train['x_min']\n",
    "    # X_train['y_maxmin_diff'] = X_train['y_max'] - X_train['y_min']\n",
    "    # X_train['z_maxmin_diff'] = X_train['z_max'] - X_train['z_min']\n",
    "\n",
    "    # median\n",
    "    X_train['x_median'] = pd.Series(x_list_train).apply(lambda x: np.median(x))\n",
    "    X_train['y_median'] = pd.Series(y_list_train).apply(lambda x: np.median(x))\n",
    "    X_train['z_median'] = pd.Series(z_list_train).apply(lambda x: np.median(x))\n",
    "\n",
    "    # median abs dev \n",
    "    X_train['x_mad'] = pd.Series(x_list_train).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X_train['y_mad'] = pd.Series(y_list_train).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X_train['z_mad'] = pd.Series(z_list_train).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "\n",
    "    # interquartile range\n",
    "    X_train['x_IQR'] = pd.Series(x_list_train).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X_train['y_IQR'] = pd.Series(y_list_train).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X_train['z_IQR'] = pd.Series(z_list_train).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "\n",
    "    # negtive count\n",
    "    X_train['x_neg_count'] = pd.Series(x_list_train).apply(lambda x: np.sum(x < 0))\n",
    "    X_train['y_neg_count'] = pd.Series(y_list_train).apply(lambda x: np.sum(x < 0))\n",
    "    X_train['z_neg_count'] = pd.Series(z_list_train).apply(lambda x: np.sum(x < 0))\n",
    "\n",
    "    # positive count\n",
    "    X_train['x_pos_count'] = pd.Series(x_list_train).apply(lambda x: np.sum(x > 0))\n",
    "    X_train['y_pos_count'] = pd.Series(y_list_train).apply(lambda x: np.sum(x > 0))\n",
    "    X_train['z_pos_count'] = pd.Series(z_list_train).apply(lambda x: np.sum(x > 0))\n",
    "\n",
    "    # values above mean\n",
    "    X_train['x_above_mean'] = pd.Series(x_list_train).apply(lambda x: np.sum(x > x.mean()))\n",
    "    X_train['y_above_mean'] = pd.Series(y_list_train).apply(lambda x: np.sum(x > x.mean()))\n",
    "    X_train['z_above_mean'] = pd.Series(z_list_train).apply(lambda x: np.sum(x > x.mean()))\n",
    "\n",
    "    # number of peaks\n",
    "    X_train['x_peak_count'] = pd.Series(x_list_train).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X_train['y_peak_count'] = pd.Series(y_list_train).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X_train['z_peak_count'] = pd.Series(z_list_train).apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "    # # skewness\n",
    "    # X_train['x_skewness'] = pd.Series(x_list_train).apply(lambda x: stats.skew(x))\n",
    "    # X_train['y_skewness'] = pd.Series(y_list_train).apply(lambda x: stats.skew(x))\n",
    "    # X_train['z_skewness'] = pd.Series(z_list_train).apply(lambda x: stats.skew(x))\n",
    "\n",
    "    # # kurtosis\n",
    "    # X_train['x_kurtosis'] = pd.Series(x_list_train).apply(lambda x: stats.kurtosis(x))\n",
    "    # X_train['y_kurtosis'] = pd.Series(y_list_train).apply(lambda x: stats.kurtosis(x))\n",
    "    # X_train['z_kurtosis'] = pd.Series(z_list_train).apply(lambda x: stats.kurtosis(x))\n",
    "\n",
    "    # energy\n",
    "    X_train['x_energy'] = pd.Series(x_list_train).apply(lambda x: np.sum(x**2)/window_size)\n",
    "    X_train['y_energy'] = pd.Series(y_list_train).apply(lambda x: np.sum(x**2)/window_size)\n",
    "    X_train['z_energy'] = pd.Series(z_list_train).apply(lambda x: np.sum(x**2)/window_size)\n",
    "\n",
    "    # avg resultant\n",
    "    X_train['avg_result_accl'] = [i.mean() for i in ((pd.Series(x_list_train)**2 + pd.Series(y_list_train)**2 + pd.Series(z_list_train)**2)**0.5)]\n",
    "\n",
    "    # signal magnitude area\n",
    "    X_train['sma'] =    pd.Series(x_list_train).apply(lambda x: np.sum(abs(x)/window_size)) + pd.Series(y_list_train).apply(lambda x: np.sum(abs(x)/window_size)) \\\n",
    "                    + pd.Series(z_list_train).apply(lambda x: np.sum(abs(x)/window_size))\n",
    "    \n",
    "    # x_list_fft_train = pd.Series(x_list_train).apply(lambda x: np.abs(np.fft.fft(x))[1:step_size])\n",
    "    # y_list_fft_train = pd.Series(y_list_train).apply(lambda x: np.abs(np.fft.fft(x))[1:step_size])\n",
    "    # z_list_fft_train = pd.Series(z_list_train).apply(lambda x: np.abs(np.fft.fft(x))[1:step_size])\n",
    "\n",
    "    # # Statistical Features on raw x, y and z in frequency domain\n",
    "    # # FFT mean\n",
    "    # X_train['x_mean_fft'] = pd.Series(x_list_fft_train).apply(lambda x: x.mean())\n",
    "    # X_train['y_mean_fft'] = pd.Series(y_list_fft_train).apply(lambda x: x.mean())\n",
    "    # X_train['z_mean_fft'] = pd.Series(z_list_fft_train).apply(lambda x: x.mean())\n",
    "\n",
    "    # # FFT std dev\n",
    "    # X_train['x_std_fft'] = pd.Series(x_list_fft_train).apply(lambda x: x.std())\n",
    "    # X_train['y_std_fft'] = pd.Series(y_list_fft_train).apply(lambda x: x.std())\n",
    "    # X_train['z_std_fft'] = pd.Series(z_list_fft_train).apply(lambda x: x.std())\n",
    "\n",
    "    # # FFT avg absolute diff\n",
    "    # X_train['x_aad_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    # X_train['y_aad_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    # X_train['z_aad_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "\n",
    "    # # FFT min\n",
    "    # X_train['x_min_fft'] = pd.Series(x_list_fft_train).apply(lambda x: x.min())\n",
    "    # X_train['y_min_fft'] = pd.Series(y_list_fft_train).apply(lambda x: x.min())\n",
    "    # X_train['z_min_fft'] = pd.Series(z_list_fft_train).apply(lambda x: x.min())\n",
    "\n",
    "    # # FFT max\n",
    "    # X_train['x_max_fft'] = pd.Series(x_list_fft_train).apply(lambda x: x.max())\n",
    "    # X_train['y_max_fft'] = pd.Series(y_list_fft_train).apply(lambda x: x.max())\n",
    "    # X_train['z_max_fft'] = pd.Series(z_list_fft_train).apply(lambda x: x.max())\n",
    "\n",
    "    # # FFT max-min diff\n",
    "    # X_train['x_maxmin_diff_fft'] = X_train['x_max_fft'] - X_train['x_min_fft']\n",
    "    # X_train['y_maxmin_diff_fft'] = X_train['y_max_fft'] - X_train['y_min_fft']\n",
    "    # X_train['z_maxmin_diff_fft'] = X_train['z_max_fft'] - X_train['z_min_fft']\n",
    "\n",
    "    # # FFT median\n",
    "    # X_train['x_median_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.median(x))\n",
    "    # X_train['y_median_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.median(x))\n",
    "    # X_train['z_median_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.median(x))\n",
    "\n",
    "    # # FFT median abs dev \n",
    "    # X_train['x_mad_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    # X_train['y_mad_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    # X_train['z_mad_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "\n",
    "    # # FFT Interquartile range\n",
    "    # X_train['x_IQR_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    # X_train['y_IQR_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    # X_train['z_IQR_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "\n",
    "    # # FFT values above mean\n",
    "    # X_train['x_above_mean_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.sum(x > x.mean()))\n",
    "    # X_train['y_above_mean_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.sum(x > x.mean()))\n",
    "    # X_train['z_above_mean_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.sum(x > x.mean()))\n",
    "\n",
    "    # # FFT number of peaks\n",
    "    # X_train['x_peak_count_fft'] = pd.Series(x_list_fft_train).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    # X_train['y_peak_count_fft'] = pd.Series(y_list_fft_train).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    # X_train['z_peak_count_fft'] = pd.Series(z_list_fft_train).apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "    # # FFT skewness\n",
    "    # X_train['x_skewness_fft'] = pd.Series(x_list_fft_train).apply(lambda x: stats.skew(x))\n",
    "    # X_train['y_skewness_fft'] = pd.Series(y_list_fft_train).apply(lambda x: stats.skew(x))\n",
    "    # X_train['z_skewness_fft'] = pd.Series(z_list_fft_train).apply(lambda x: stats.skew(x))\n",
    "\n",
    "    # # FFT kurtosis\n",
    "    # X_train['x_kurtosis_fft'] = pd.Series(x_list_fft_train).apply(lambda x: stats.kurtosis(x))\n",
    "    # X_train['y_kurtosis_fft'] = pd.Series(y_list_fft_train).apply(lambda x: stats.kurtosis(x))\n",
    "    # X_train['z_kurtosis_fft'] = pd.Series(z_list_fft_train).apply(lambda x: stats.kurtosis(x))\n",
    "\n",
    "    # # FFT energy\n",
    "    # X_train['x_energy_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.sum(x**2)/50)\n",
    "    # X_train['y_energy_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.sum(x**2)/50)\n",
    "    # X_train['z_energy_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.sum(x**2/50))\n",
    "\n",
    "    # # FFT avg resultant\n",
    "    # X_train['avg_result_accl_fft'] = [i.mean() for i in ((pd.Series(x_list_fft_train)**2 + pd.Series(y_list_fft_train)**2 + pd.Series(z_list_fft_train)**2)**0.5)]\n",
    "\n",
    "    # # FFT Signal magnitude area\n",
    "    # X_train['sma_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.sum(abs(x)/50)) + pd.Series(y_list_fft_train).apply(lambda x: np.sum(abs(x)/50)) \\\n",
    "    #                     + pd.Series(z_list_fft_train).apply(lambda x: np.sum(abs(x)/50))\n",
    "\n",
    "    # # Max Indices and Min indices \n",
    "\n",
    "    # # index of max value in time domain\n",
    "    # X_train['x_argmax'] = pd.Series(x_list_train).apply(lambda x: np.argmax(x))\n",
    "    # X_train['y_argmax'] = pd.Series(y_list_train).apply(lambda x: np.argmax(x))\n",
    "    # X_train['z_argmax'] = pd.Series(z_list_train).apply(lambda x: np.argmax(x))\n",
    "\n",
    "    # # index of min value in time domain\n",
    "    # X_train['x_argmin'] = pd.Series(x_list_train).apply(lambda x: np.argmin(x))\n",
    "    # X_train['y_argmin'] = pd.Series(y_list_train).apply(lambda x: np.argmin(x))\n",
    "    # X_train['z_argmin'] = pd.Series(z_list_train).apply(lambda x: np.argmin(x))\n",
    "\n",
    "    # # absolute difference between above indices\n",
    "    # X_train['x_arg_diff'] = abs(X_train['x_argmax'] - X_train['x_argmin'])\n",
    "    # X_train['y_arg_diff'] = abs(X_train['y_argmax'] - X_train['y_argmin'])\n",
    "    # X_train['z_arg_diff'] = abs(X_train['z_argmax'] - X_train['z_argmin'])\n",
    "\n",
    "    # # index of max value in frequency domain\n",
    "    # X_train['x_argmax_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.argmax(np.abs(np.fft.fft(x))[1:51]))\n",
    "    # X_train['y_argmax_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.argmax(np.abs(np.fft.fft(x))[1:51]))\n",
    "    # X_train['z_argmax_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.argmax(np.abs(np.fft.fft(x))[1:51]))\n",
    "\n",
    "    # # index of min value in frequency domain\n",
    "    # X_train['x_argmin_fft'] = pd.Series(x_list_fft_train).apply(lambda x: np.argmin(np.abs(np.fft.fft(x))[1:51]))\n",
    "    # X_train['y_argmin_fft'] = pd.Series(y_list_fft_train).apply(lambda x: np.argmin(np.abs(np.fft.fft(x))[1:51]))\n",
    "    # X_train['z_argmin_fft'] = pd.Series(z_list_fft_train).apply(lambda x: np.argmin(np.abs(np.fft.fft(x))[1:51]))\n",
    "\n",
    "    # # absolute difference between above indices\n",
    "    # X_train['x_arg_diff_fft'] = abs(X_train['x_argmax_fft'] - X_train['x_argmin_fft'])\n",
    "    # X_train['y_arg_diff_fft'] = abs(X_train['y_argmax_fft'] - X_train['y_argmin_fft'])\n",
    "    # X_train['z_arg_diff_fft'] = abs(X_train['z_argmax_fft'] - X_train['z_argmin_fft'])\n",
    "\n",
    "\n",
    "    ### X TEST\n",
    "    x_list_test = []\n",
    "    y_list_test = []\n",
    "    z_list_test = []\n",
    "    test_labels = []\n",
    "\n",
    "    # creating overlaping windows of size window-size\n",
    "    for i in range(0, df_test.shape[0] - window_size, step_size):\n",
    "        xs = df_test['ax'].values[i: i + window_size]\n",
    "        ys = df_test['ay'].values[i: i + window_size]\n",
    "        zs = df_test['az'].values[i: i + window_size]\n",
    "        label = stats.mode(df_test['Actividades'][i: i + window_size])[0][0]\n",
    "\n",
    "        x_list_test.append(xs)\n",
    "        y_list_test.append(ys)\n",
    "        z_list_test.append(zs)\n",
    "        test_labels.append(label)\n",
    "\n",
    "    # Statistical Features on raw x, y and z in time domain\n",
    "    X_test = pd.DataFrame()\n",
    "\n",
    "    # mean\n",
    "    X_test['x_mean'] = pd.Series(x_list_test).apply(lambda x: x.mean())\n",
    "    X_test['y_mean'] = pd.Series(y_list_test).apply(lambda x: x.mean())\n",
    "    X_test['z_mean'] = pd.Series(z_list_test).apply(lambda x: x.mean())\n",
    "\n",
    "    # std dev\n",
    "    X_test['x_std'] = pd.Series(x_list_test).apply(lambda x: x.std())\n",
    "    X_test['y_std'] = pd.Series(y_list_test).apply(lambda x: x.std())\n",
    "    X_test['z_std'] = pd.Series(z_list_test).apply(lambda x: x.std())\n",
    "\n",
    "    # avg absolute diff\n",
    "    X_test['x_aad'] = pd.Series(x_list_test).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X_test['y_aad'] = pd.Series(y_list_test).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X_test['z_aad'] = pd.Series(z_list_test).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "\n",
    "    # min\n",
    "    X_test['x_min'] = pd.Series(x_list_test).apply(lambda x: x.min())\n",
    "    X_test['y_min'] = pd.Series(y_list_test).apply(lambda x: x.min())\n",
    "    X_test['z_min'] = pd.Series(z_list_test).apply(lambda x: x.min())\n",
    "\n",
    "    # max\n",
    "    X_test['x_max'] = pd.Series(x_list_test).apply(lambda x: x.max())\n",
    "    X_test['y_max'] = pd.Series(y_list_test).apply(lambda x: x.max())\n",
    "    X_test['z_max'] = pd.Series(z_list_test).apply(lambda x: x.max())\n",
    "\n",
    "    # #max-min diff\n",
    "    # X_test['x_maxmin_diff'] = X_test['x_max'] - X_test['x_min']\n",
    "    # X_test['y_maxmin_diff'] = X_test['y_max'] - X_test['y_min']\n",
    "    # X_test['z_maxmin_diff'] = X_test['z_max'] - X_test['z_min']\n",
    "\n",
    "    # median\n",
    "    X_test['x_median'] = pd.Series(x_list_test).apply(lambda x: np.median(x))\n",
    "    X_test['y_median'] = pd.Series(y_list_test).apply(lambda x: np.median(x))\n",
    "    X_test['z_median'] = pd.Series(z_list_test).apply(lambda x: np.median(x))\n",
    "\n",
    "    # median abs dev \n",
    "    X_test['x_mad'] = pd.Series(x_list_test).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X_test['y_mad'] = pd.Series(y_list_test).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X_test['z_mad'] = pd.Series(z_list_test).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "\n",
    "    # interquartile range\n",
    "    X_test['x_IQR'] = pd.Series(x_list_test).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X_test['y_IQR'] = pd.Series(y_list_test).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X_test['z_IQR'] = pd.Series(z_list_test).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "\n",
    "    # negtive count\n",
    "    X_test['x_neg_count'] = pd.Series(x_list_test).apply(lambda x: np.sum(x < 0))\n",
    "    X_test['y_neg_count'] = pd.Series(y_list_test).apply(lambda x: np.sum(x < 0))\n",
    "    X_test['z_neg_count'] = pd.Series(z_list_test).apply(lambda x: np.sum(x < 0))\n",
    "\n",
    "    # positive count\n",
    "    X_test['x_pos_count'] = pd.Series(x_list_test).apply(lambda x: np.sum(x > 0))\n",
    "    X_test['y_pos_count'] = pd.Series(y_list_test).apply(lambda x: np.sum(x > 0))\n",
    "    X_test['z_pos_count'] = pd.Series(z_list_test).apply(lambda x: np.sum(x > 0))\n",
    "\n",
    "    # values above mean\n",
    "    X_test['x_above_mean'] = pd.Series(x_list_test).apply(lambda x: np.sum(x > x.mean()))\n",
    "    X_test['y_above_mean'] = pd.Series(y_list_test).apply(lambda x: np.sum(x > x.mean()))\n",
    "    X_test['z_above_mean'] = pd.Series(z_list_test).apply(lambda x: np.sum(x > x.mean()))\n",
    "\n",
    "    # number of peaks\n",
    "    X_test['x_peak_count'] = pd.Series(x_list_test).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X_test['y_peak_count'] = pd.Series(y_list_test).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X_test['z_peak_count'] = pd.Series(z_list_test).apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "    # # skewness\n",
    "    # X_test['x_skewness'] = pd.Series(x_list_test).apply(lambda x: stats.skew(x))\n",
    "    # X_test['y_skewness'] = pd.Series(y_list_test).apply(lambda x: stats.skew(x))\n",
    "    # X_test['z_skewness'] = pd.Series(z_list_test).apply(lambda x: stats.skew(x))\n",
    "\n",
    "    # # kurtosis\n",
    "    # X_test['x_kurtosis'] = pd.Series(x_list_test).apply(lambda x: stats.kurtosis(x))\n",
    "    # X_test['y_kurtosis'] = pd.Series(y_list_test).apply(lambda x: stats.kurtosis(x))\n",
    "    # X_test['z_kurtosis'] = pd.Series(z_list_test).apply(lambda x: stats.kurtosis(x))\n",
    "\n",
    "    # energy\n",
    "    X_test['x_energy'] = pd.Series(x_list_test).apply(lambda x: np.sum(x**2)/window_size)\n",
    "    X_test['y_energy'] = pd.Series(y_list_test).apply(lambda x: np.sum(x**2)/window_size)\n",
    "    X_test['z_energy'] = pd.Series(z_list_test).apply(lambda x: np.sum(x**2)/window_size)\n",
    "\n",
    "    # avg resultant\n",
    "    X_test['avg_result_accl'] = [i.mean() for i in ((pd.Series(x_list_test)**2 + pd.Series(y_list_test)**2 + pd.Series(z_list_test)**2)**0.5)]\n",
    "\n",
    "    # signal magnitude area\n",
    "    X_test['sma'] =    pd.Series(x_list_test).apply(lambda x: np.sum(abs(x)/window_size)) + pd.Series(y_list_test).apply(lambda x: np.sum(abs(x)/window_size)) \\\n",
    "                    + pd.Series(z_list_test).apply(lambda x: np.sum(abs(x)/window_size))\n",
    "    \n",
    "    # converting the signals from time domain to frequency domain using FFT\n",
    "\n",
    "    # # converting the signals from time domain to frequency domain using FFT\n",
    "    # x_list_fft_test = pd.Series(x_list_test).apply(lambda x: np.abs(np.fft.fft(x))[1:step_size])\n",
    "    # y_list_fft_test = pd.Series(y_list_test).apply(lambda x: np.abs(np.fft.fft(x))[1:step_size])\n",
    "    # z_list_fft_test = pd.Series(z_list_test).apply(lambda x: np.abs(np.fft.fft(x))[1:step_size])\n",
    "\n",
    "    # # Statistical Features on raw x, y and z in frequency domain\n",
    "    # # FFT mean\n",
    "    # X_test['x_mean_fft'] = pd.Series(x_list_fft_test).apply(lambda x: x.mean())\n",
    "    # X_test['y_mean_fft'] = pd.Series(y_list_fft_test).apply(lambda x: x.mean())\n",
    "    # X_test['z_mean_fft'] = pd.Series(z_list_fft_test).apply(lambda x: x.mean())\n",
    "\n",
    "    # # FFT std dev\n",
    "    # X_test['x_std_fft'] = pd.Series(x_list_fft_test).apply(lambda x: x.std())\n",
    "    # X_test['y_std_fft'] = pd.Series(y_list_fft_test).apply(lambda x: x.std())\n",
    "    # X_test['z_std_fft'] = pd.Series(z_list_fft_test).apply(lambda x: x.std())\n",
    "\n",
    "    # # FFT avg absolute diff\n",
    "    # X_test['x_aad_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    # X_test['y_aad_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    # X_test['z_aad_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "\n",
    "    # # FFT min\n",
    "    # X_test['x_min_fft'] = pd.Series(x_list_fft_test).apply(lambda x: x.min())\n",
    "    # X_test['y_min_fft'] = pd.Series(y_list_fft_test).apply(lambda x: x.min())\n",
    "    # X_test['z_min_fft'] = pd.Series(z_list_fft_test).apply(lambda x: x.min())\n",
    "\n",
    "    # # FFT max\n",
    "    # X_test['x_max_fft'] = pd.Series(x_list_fft_test).apply(lambda x: x.max())\n",
    "    # X_test['y_max_fft'] = pd.Series(y_list_fft_test).apply(lambda x: x.max())\n",
    "    # X_test['z_max_fft'] = pd.Series(z_list_fft_test).apply(lambda x: x.max())\n",
    "\n",
    "    # # FFT max-min diff\n",
    "    # X_test['x_maxmin_diff_fft'] = X_test['x_max_fft'] - X_test['x_min_fft']\n",
    "    # X_test['y_maxmin_diff_fft'] = X_test['y_max_fft'] - X_test['y_min_fft']\n",
    "    # X_test['z_maxmin_diff_fft'] = X_test['z_max_fft'] - X_test['z_min_fft']\n",
    "\n",
    "    # # FFT median\n",
    "    # X_test['x_median_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.median(x))\n",
    "    # X_test['y_median_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.median(x))\n",
    "    # X_test['z_median_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.median(x))\n",
    "\n",
    "    # # FFT median abs dev \n",
    "    # X_test['x_mad_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    # X_test['y_mad_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    # X_test['z_mad_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "\n",
    "    # # FFT Interquartile range\n",
    "    # X_test['x_IQR_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    # X_test['y_IQR_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    # X_test['z_IQR_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "\n",
    "    # # FFT values above mean\n",
    "    # X_test['x_above_mean_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.sum(x > x.mean()))\n",
    "    # X_test['y_above_mean_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.sum(x > x.mean()))\n",
    "    # X_test['z_above_mean_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.sum(x > x.mean()))\n",
    "\n",
    "    # # FFT number of peaks\n",
    "    # X_test['x_peak_count_fft'] = pd.Series(x_list_fft_test).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    # X_test['y_peak_count_fft'] = pd.Series(y_list_fft_test).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    # X_test['z_peak_count_fft'] = pd.Series(z_list_fft_test).apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "    # # FFT skewness\n",
    "    # X_test['x_skewness_fft'] = pd.Series(x_list_fft_test).apply(lambda x: stats.skew(x))\n",
    "    # X_test['y_skewness_fft'] = pd.Series(y_list_fft_test).apply(lambda x: stats.skew(x))\n",
    "    # X_test['z_skewness_fft'] = pd.Series(z_list_fft_test).apply(lambda x: stats.skew(x))\n",
    "\n",
    "    # # FFT kurtosis\n",
    "    # X_test['x_kurtosis_fft'] = pd.Series(x_list_fft_test).apply(lambda x: stats.kurtosis(x))\n",
    "    # X_test['y_kurtosis_fft'] = pd.Series(y_list_fft_test).apply(lambda x: stats.kurtosis(x))\n",
    "    # X_test['z_kurtosis_fft'] = pd.Series(z_list_fft_test).apply(lambda x: stats.kurtosis(x))\n",
    "\n",
    "    # # FFT energy\n",
    "    # X_test['x_energy_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.sum(x**2)/50)\n",
    "    # X_test['y_energy_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.sum(x**2)/50)\n",
    "    # X_test['z_energy_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.sum(x**2/50))\n",
    "\n",
    "    # # FFT avg resultant\n",
    "    # X_test['avg_result_accl_fft'] = [i.mean() for i in ((pd.Series(x_list_fft_test)**2 + pd.Series(y_list_fft_test)**2 + pd.Series(z_list_fft_test)**2)**0.5)]\n",
    "\n",
    "    # # FFT Signal magnitude area\n",
    "    # X_test['sma_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.sum(abs(x)/50)) + pd.Series(y_list_fft_test).apply(lambda x: np.sum(abs(x)/50)) \\\n",
    "    #                     + pd.Series(z_list_fft_test).apply(lambda x: np.sum(abs(x)/50))\n",
    "\n",
    "    # # Max Indices and Min indices \n",
    "\n",
    "    # # index of max value in time domain\n",
    "    # X_test['x_argmax'] = pd.Series(x_list_test).apply(lambda x: np.argmax(x))\n",
    "    # X_test['y_argmax'] = pd.Series(y_list_test).apply(lambda x: np.argmax(x))\n",
    "    # X_test['z_argmax'] = pd.Series(z_list_test).apply(lambda x: np.argmax(x))\n",
    "\n",
    "    # # index of min value in time domain\n",
    "    # X_test['x_argmin'] = pd.Series(x_list_test).apply(lambda x: np.argmin(x))\n",
    "    # X_test['y_argmin'] = pd.Series(y_list_test).apply(lambda x: np.argmin(x))\n",
    "    # X_test['z_argmin'] = pd.Series(z_list_test).apply(lambda x: np.argmin(x))\n",
    "\n",
    "    # # absolute difference between above indices\n",
    "    # X_test['x_arg_diff'] = abs(X_test['x_argmax'] - X_test['x_argmin'])\n",
    "    # X_test['y_arg_diff'] = abs(X_test['y_argmax'] - X_test['y_argmin'])\n",
    "    # X_test['z_arg_diff'] = abs(X_test['z_argmax'] - X_test['z_argmin'])\n",
    "\n",
    "    # # index of max value in frequency domain\n",
    "    # X_test['x_argmax_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.argmax(np.abs(np.fft.fft(x))[1:51]))\n",
    "    # X_test['y_argmax_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.argmax(np.abs(np.fft.fft(x))[1:51]))\n",
    "    # X_test['z_argmax_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.argmax(np.abs(np.fft.fft(x))[1:51]))\n",
    "\n",
    "    # # index of min value in frequency domain\n",
    "    # X_test['x_argmin_fft'] = pd.Series(x_list_fft_test).apply(lambda x: np.argmin(np.abs(np.fft.fft(x))[1:51]))\n",
    "    # X_test['y_argmin_fft'] = pd.Series(y_list_fft_test).apply(lambda x: np.argmin(np.abs(np.fft.fft(x))[1:51]))\n",
    "    # X_test['z_argmin_fft'] = pd.Series(z_list_fft_test).apply(lambda x: np.argmin(np.abs(np.fft.fft(x))[1:51]))\n",
    "\n",
    "    # # absolute difference between above indices\n",
    "    # X_test['x_arg_diff_fft'] = abs(X_test['x_argmax_fft'] - X_test['x_argmin_fft'])\n",
    "    # X_test['y_arg_diff_fft'] = abs(X_test['y_argmax_fft'] - X_test['y_argmin_fft'])\n",
    "    # X_test['z_arg_diff_fft'] = abs(X_test['z_argmax_fft'] - X_test['z_argmin_fft'])\n",
    "    \n",
    "\n",
    "    act = np.array(train_labels)\n",
    "    act_test = np.array(test_labels)\n",
    "\n",
    "    # X_train.fillna(0)\n",
    "    # X_test.fillna(0)\n",
    "    #removing null values\n",
    "    # X_test = X_test.dropna()\n",
    "    # X_test.shape\n",
    "    # X_train=X_train.dropna()\n",
    "    # X_train.shape\n",
    "\n",
    "\n",
    "    ### Modelo regresión lineal\n",
    "    # standardization\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_data_lr = scaler.transform(X_train)\n",
    "    X_test_data_lr = scaler.transform(X_test)\n",
    "    # logistic regression model\n",
    "    lr = LogisticRegression(random_state = 21)\n",
    "    lr.fit(X_train_data_lr, act)\n",
    "    act_pred_lr = lr.predict(X_test_data_lr)\n",
    "    accuracyX = accuracy_score(act_test, act_pred_lr)\n",
    "    accuracyX_lr.append(accuracyX)\n",
    "\n",
    "    precision_recall_fscore_lr = precision_recall_fscore_support(act_test,act_pred_lr,average=None)\n",
    "    precisionX_lr.append(precision_recall_fscore_lr[0])\n",
    "    recallX_lr.append(precision_recall_fscore_lr[1])\n",
    "    fscoreX_lr.append(precision_recall_fscore_lr[2])\n",
    "    \n",
    "    act = np.array(train_labels)\n",
    "    act_test = np.array(test_labels)\n",
    "\n",
    "    # # Generar la matriz de confusión\n",
    "    # confusion_matrix_lf = confusion_matrix(act_test, act_pred_lr)\n",
    "\n",
    "    # # Crear figura y ejes\n",
    "    # fig, ax1 = plt.subplots()\n",
    "    # im = ax1.imshow(confusion_matrix_lf, cmap='YlGnBu')  # Cambiar el colormap aquí\n",
    "\n",
    "    # # Mostrar todas las etiquetas de las clases\n",
    "    # ax1.set_xticks(np.arange(len(labels)))\n",
    "    # ax1.set_yticks(np.arange(len(labels)))\n",
    "    # ax1.set_xticklabels(labels)\n",
    "    # ax1.set_yticklabels(labels)\n",
    "\n",
    "    # # Rotar las etiquetas para que sean legibles\n",
    "    # plt.setp(ax1.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # # Mostrar los valores de cada celda\n",
    "    # for i in range(len(labels)):\n",
    "    #     for j in range(len(labels)):\n",
    "    #         text=ax1.text(j, i, confusion_matrix_lf[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "    # # Configuración del título y etiquetas de los ejes\n",
    "    # plt.title(\"Confusion matrix Regresión lineal\")\n",
    "    # plt.xlabel('Predicted label')\n",
    "    # plt.ylabel('True label')\n",
    "\n",
    "    # # Agregar la barra de referencia al lado\n",
    "    # plt.colorbar(im, ax=ax1)\n",
    "\n",
    "    # # Eliminar las líneas divisorias entre los cuadrados\n",
    "    # plt.gca().spines['top'].set_visible(False)\n",
    "    # plt.gca().spines['right'].set_visible(False)\n",
    "    # plt.gca().spines['bottom'].set_visible(False)\n",
    "    # plt.gca().spines['left'].set_visible(False)\n",
    "    # plt.tick_params(axis=u'both', which=u'both',length=0)\n",
    "    # ax1.grid(False)\n",
    "    # plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # standardization\n",
    "    X_train_data_rf = scaler.transform(X_train)\n",
    "    X_test_data_rf = scaler.transform(X_test)\n",
    "    #Entrenar el modelo\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train_data_rf, act)\n",
    "    act_pred_rf = rf.predict(X_test_data_rf)\n",
    "    accuracyX = accuracy_score(act_test, act_pred_rf)\n",
    "    accuracyX_rf.append(accuracyX)\n",
    "    # recallX= recall_score(act_test,act_pred_rf, average = None)\n",
    "    # recallX_rf.append(recallX)\n",
    "    precision_recall_fscore_rf = precision_recall_fscore_support(act_test,act_pred_rf,average=None)\n",
    "    precisionX_rf.append(precision_recall_fscore_rf[0])\n",
    "    recallX_rf.append(precision_recall_fscore_rf[1])\n",
    "    fscoreX_rf.append(precision_recall_fscore_rf[2])\n",
    "\n",
    "    #Descomentar de acá al final si se quieren graficar las matrices de confusión para cada tamaño de ventana\n",
    "\n",
    "    # # Generar la matriz de confusión\n",
    "    # confusion_matrix_rf = confusion_matrix(act_test, act_pred_rf)\n",
    "\n",
    "    # # Crear figura y ejes\n",
    "    # fig, ax2 = plt.subplots()\n",
    "    # im = ax2.imshow(confusion_matrix_rf, cmap='YlGnBu')  # Cambiar el colormap aquí\n",
    "\n",
    "    # # Mostrar todas las etiquetas de las clases\n",
    "    # ax2.set_xticks(np.arange(len(labels)))\n",
    "    # ax2.set_yticks(np.arange(len(labels)))\n",
    "    # ax2.set_xticklabels(labels)\n",
    "    # ax2.set_yticklabels(labels)\n",
    "\n",
    "    # # Rotar las etiquetas para que sean legibles\n",
    "    # plt.setp(ax2.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # # Mostrar los valores de cada celda\n",
    "    # for i in range(len(labels)):\n",
    "    #     for j in range(len(labels)):\n",
    "    #         text=ax2.text(j, i, confusion_matrix_rf[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "    # # Configuración del título y etiquetas de los ejes\n",
    "    # plt.title(\"Confusion matrix Random Forest\")\n",
    "    # plt.xlabel('Predicted label')\n",
    "    # plt.ylabel('True label')\n",
    "\n",
    "    # # Agregar la barra de referencia al lado\n",
    "    # plt.colorbar(im, ax=ax2)\n",
    "\n",
    "    # # Eliminar las líneas divisorias entre los cuadrados\n",
    "    # plt.gca().spines['top'].set_visible(False)\n",
    "    # plt.gca().spines['right'].set_visible(False)\n",
    "    # plt.gca().spines['bottom'].set_visible(False)\n",
    "    # plt.gca().spines['left'].set_visible(False)\n",
    "    # plt.tick_params(axis=u'both', which=u'both',length=0)\n",
    "    # ax2.grid(False)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "precision_mov_1_rf = [array[1] for array in precisionX_rf]\n",
    "precision_mov_2_rf = [array[2] for array in precisionX_rf]\n",
    "precision_mov_3_rf = [array[3] for array in precisionX_rf]\n",
    "precision_mov_4_rf = [array[4] for array in precisionX_rf]\n",
    "precision_quieto_rf = [array[0] for array in precisionX_rf]\n",
    "fig, axs = plt.subplots(1, sharex=True, sharey=True)\n",
    "#axs.plot(windows, recallX_lr, label='Regresión lineal')\n",
    "axs.plot(windows, precision_mov_1_rf, label='Movimiento 1')\n",
    "axs.plot(windows, precision_mov_2_rf, label='Movimiento 2')\n",
    "axs.plot(windows, precision_mov_3_rf, label='Movimiento 3')\n",
    "axs.plot(windows, precision_mov_4_rf, label='Movimiento 4')\n",
    "axs.plot(windows, precision_quieto_rf, label='Quieto')\n",
    "\n",
    "axs.set(xlabel='Tamaño de ventanas', ylabel='Precisión')\n",
    "axs.set_title('Random forest')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "precision_mov_1_lr = [array[1] for array in precisionX_lr]\n",
    "precision_mov_2_lr = [array[2] for array in precisionX_lr]\n",
    "precision_mov_3_lr = [array[3] for array in precisionX_lr]\n",
    "precision_mov_4_lr = [array[4] for array in precisionX_lr]\n",
    "precision_quieto_lr = [array[0] for array in precisionX_lr]\n",
    "fig, axs = plt.subplots(1, sharex=True, sharey=True)\n",
    "#axs.plot(windows, recallX_lr, label='Regresión lineal')\n",
    "axs.plot(windows, precision_mov_1_lr, label='Movimiento 1')\n",
    "axs.plot(windows, precision_mov_2_lr, label='Movimiento 2')\n",
    "axs.plot(windows, precision_mov_3_lr, label='Movimiento 3')\n",
    "axs.plot(windows, precision_mov_4_lr, label='Movimiento 4')\n",
    "axs.plot(windows, precision_quieto_lr, label='Quieto')\n",
    "\n",
    "axs.set(xlabel='Tamaño de ventanas', ylabel='Recall')\n",
    "axs.set_title('Regresión lineal')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "recall_mov_1_rf = [array[0] for array in recallX_rf]\n",
    "recall_mov_2_rf = [array[1] for array in recallX_rf]\n",
    "recall_mov_3_rf = [array[2] for array in recallX_rf]\n",
    "recall_mov_4_rf = [array[3] for array in recallX_rf]\n",
    "recall_quieto_rf = [array[0] for array in recallX_rf]\n",
    "fig, axs = plt.subplots(1, sharex=True, sharey=True)\n",
    "#axs.plot(windows, recallX_lr, label='Regresión lineal')\n",
    "axs.plot(windows, recall_mov_1_rf, label='Movimiento 1')\n",
    "axs.plot(windows, recall_mov_2_rf, label='Movimiento 2')\n",
    "axs.plot(windows, recall_mov_3_rf, label='Movimiento 3')\n",
    "axs.plot(windows, recall_mov_4_rf, label='Movimiento 4')\n",
    "axs.plot(windows, recall_quieto_rf, label='Quieto')\n",
    "\n",
    "axs.set(xlabel='Tamaño de ventanas', ylabel='Recall')\n",
    "axs.set_title('Random forest')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "recall_mov_1_lr = [array[1] for array in recallX_lr]\n",
    "recall_mov_2_lr = [array[2] for array in recallX_lr]\n",
    "recall_mov_3_lr = [array[3] for array in recallX_lr]\n",
    "recall_mov_4_lr = [array[4] for array in recallX_lr]\n",
    "recall_quieto_lr = [array[0] for array in recallX_lr]\n",
    "fig, axs = plt.subplots(1, sharex=True, sharey=True)\n",
    "#axs.plot(windows, recallX_lr, label='Regresión lineal')\n",
    "axs.plot(windows, recall_mov_1_lr, label='Movimiento 1')\n",
    "axs.plot(windows, recall_mov_2_lr, label='Movimiento 2')\n",
    "axs.plot(windows, recall_mov_3_lr, label='Movimiento 3')\n",
    "axs.plot(windows, recall_mov_4_lr, label='Movimiento 4')\n",
    "axs.plot(windows, recall_quieto_lr, label='Quieto')\n",
    "\n",
    "axs.set(xlabel='Tamaño de ventanas', ylabel='Recall')\n",
    "axs.set_title('Regresión lineal')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fscore_mov_1_rf = [array[1] for array in fscoreX_rf]\n",
    "fscore_mov_2_rf = [array[2] for array in fscoreX_rf]\n",
    "fscore_mov_3_rf = [array[3] for array in fscoreX_rf]\n",
    "fscore_mov_4_rf = [array[4] for array in fscoreX_rf]\n",
    "fscore_quieto_rf = [array[0] for array in fscoreX_rf]\n",
    "fig, axs = plt.subplots(1, sharex=True, sharey=True)\n",
    "#axs.plot(windows, recallX_lr, label='Regresión lineal')\n",
    "axs.plot(windows, fscore_mov_1_rf, label='Movimiento 1')\n",
    "axs.plot(windows, fscore_mov_2_rf, label='Movimiento 2')\n",
    "axs.plot(windows, fscore_mov_3_rf, label='Movimiento 3')\n",
    "axs.plot(windows, fscore_mov_4_rf, label='Movimiento 4')\n",
    "axs.plot(windows, fscore_quieto_rf, label='Quieto')\n",
    "\n",
    "axs.set(xlabel='Tamaño de ventanas', ylabel='f1_score')\n",
    "axs.set_title('Regresión lineal')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fscore_mov_1_lr = [array[1] for array in fscoreX_lr]\n",
    "fscore_mov_2_lr = [array[2] for array in fscoreX_lr]\n",
    "fscore_mov_3_lr = [array[3] for array in fscoreX_lr]\n",
    "fscore_mov_4_lr = [array[4] for array in fscoreX_lr]\n",
    "fscore_quieto_lr = [array[0] for array in fscoreX_lr]\n",
    "fig, axs = plt.subplots(1, sharex=True, sharey=True)\n",
    "#axs.plot(windows, recallX_lr, label='Regresión lineal')\n",
    "axs.plot(windows, fscore_mov_1_lr, label='Movimiento 1')\n",
    "axs.plot(windows, fscore_mov_2_lr, label='Movimiento 2')\n",
    "axs.plot(windows, fscore_mov_3_lr, label='Movimiento 3')\n",
    "axs.plot(windows, fscore_mov_4_lr, label='Movimiento 4')\n",
    "axs.plot(windows, fscore_quieto_lr, label='Quieto')\n",
    "\n",
    "axs.set(xlabel='Tamaño de ventanas', ylabel='f1_score')\n",
    "axs.set_title('Random forest')\n",
    "\n",
    "plt.legend(loc=(0.2, 0.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs tamaño ventanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, sharex=True, sharey=True)\n",
    "axs.plot(windows, accuracyX_lr, label='Regresión lineal')\n",
    "axs.plot(windows, accuracyX_rf, label='Random Forest')\n",
    "\n",
    "axs.set(xlabel='Tamaño de ventanas', ylabel='Exactitud')\n",
    "axs.set_title('Exactitud de los modelos vs tamaño de ventanas')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
