{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib qt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etiquetas de las clases\n",
    "labels = ['Caminando', 'Quieta', 'Comiendo']\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "### TRAIN\n",
    "# reading raw data file\n",
    "data_train = pd.read_csv('Archivos_CSV_con_etiquetas/train_tortuga.csv')\n",
    "data_train = data_train.drop(['gx','gy','gz'], axis=1)\n",
    "# removing null values\n",
    "data_train = data_train.dropna()\n",
    "data_train.shape\n",
    "# drop the rows where timestamp is 0\n",
    "df = data_train[pd.to_datetime(data_train['dateTime_UTC']) != 0]\n",
    "# now arrange data in ascending order of the user and timestamp\n",
    "df = df.sort_values(by = ['dateTime_UTC'], ignore_index=True)\n",
    "\n",
    "\n",
    "### TEST\n",
    "# reading raw data file\n",
    "data_test = pd.read_csv('Archivos_CSV_con_etiquetas/test_tortuga.csv')\n",
    "data_test = data_test.drop(['gx','gy','gz'], axis=1)\n",
    "# removing null values\n",
    "data_test = data_test.dropna()\n",
    "data_test.shape\n",
    "# drop the rows where timestamp is 0\n",
    "df_test = data_test[pd.to_datetime(data_test['dateTime_UTC']) != 0]\n",
    "# now arrange data in ascending order of the user and timestamp\n",
    "df_test = df_test.sort_values(by = ['dateTime_UTC'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyX_lr = []\n",
    "accuracyX_rf = []\n",
    "precisionX_rf = []\n",
    "precisionX_lr = []\n",
    "recallX_lr = []\n",
    "recallX_rf = []\n",
    "fscoreX_lr = []\n",
    "fscoreX_rf = []\n",
    "precisionX_rf_W = []\n",
    "precisionX_lr_W = []\n",
    "recallX_lr_W = []\n",
    "recallX_rf_W = []\n",
    "fscoreX_lr_W = []\n",
    "fscoreX_rf_W = []\n",
    "windows = []\n",
    "\n",
    "for i in range(11):\n",
    "    \n",
    "    step_size=1+48*i\n",
    "    \n",
    "    window_size=2*step_size\n",
    "    df_train = data_train\n",
    "    df_test=data_test\n",
    "    windows.append(window_size)\n",
    "\n",
    "\n",
    "    ### X TRAIN\n",
    "    x_list_train = []\n",
    "    y_list_train = []\n",
    "    z_list_train = []\n",
    "    train_labels = []\n",
    "\n",
    "    # creating overlaping windows of size window-size\n",
    "    for i in range(0, df_train.shape[0] - window_size, step_size):\n",
    "        xs = df_train['ax'].values[i: i + window_size]\n",
    "        ys = df_train['ay'].values[i: i + window_size]\n",
    "        zs = df_train['az'].values[i: i + window_size]\n",
    "        label = stats.mode(df_train['Actividades'][i: i + window_size])[0][0]\n",
    "\n",
    "        x_list_train.append(xs)\n",
    "        y_list_train.append(ys)\n",
    "        z_list_train.append(zs)\n",
    "        train_labels.append(label)\n",
    "\n",
    "    # Statistical Features on raw x, y and z in time domain\n",
    "    X_train = pd.DataFrame()\n",
    "\n",
    "    # mean\n",
    "    X_train['x_mean'] = pd.Series(x_list_train).apply(lambda x: x.mean())\n",
    "    X_train['y_mean'] = pd.Series(y_list_train).apply(lambda x: x.mean())\n",
    "    X_train['z_mean'] = pd.Series(z_list_train).apply(lambda x: x.mean())\n",
    "\n",
    "    # std dev\n",
    "    X_train['x_std'] = pd.Series(x_list_train).apply(lambda x: x.std())\n",
    "    X_train['y_std'] = pd.Series(y_list_train).apply(lambda x: x.std())\n",
    "    X_train['z_std'] = pd.Series(z_list_train).apply(lambda x: x.std())\n",
    "\n",
    "    # avg absolute diff\n",
    "    X_train['x_aad'] = pd.Series(x_list_train).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X_train['y_aad'] = pd.Series(y_list_train).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X_train['z_aad'] = pd.Series(z_list_train).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "\n",
    "    # min\n",
    "    X_train['x_min'] = pd.Series(x_list_train).apply(lambda x: x.min())\n",
    "    X_train['y_min'] = pd.Series(y_list_train).apply(lambda x: x.min())\n",
    "    X_train['z_min'] = pd.Series(z_list_train).apply(lambda x: x.min())\n",
    "\n",
    "    # max\n",
    "    X_train['x_max'] = pd.Series(x_list_train).apply(lambda x: x.max())\n",
    "    X_train['y_max'] = pd.Series(y_list_train).apply(lambda x: x.max())\n",
    "    X_train['z_max'] = pd.Series(z_list_train).apply(lambda x: x.max())\n",
    "\n",
    "\n",
    "\n",
    "    # median\n",
    "    X_train['x_median'] = pd.Series(x_list_train).apply(lambda x: np.median(x))\n",
    "    X_train['y_median'] = pd.Series(y_list_train).apply(lambda x: np.median(x))\n",
    "    X_train['z_median'] = pd.Series(z_list_train).apply(lambda x: np.median(x))\n",
    "\n",
    "    # median abs dev \n",
    "    X_train['x_mad'] = pd.Series(x_list_train).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X_train['y_mad'] = pd.Series(y_list_train).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X_train['z_mad'] = pd.Series(z_list_train).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "\n",
    "    # interquartile range\n",
    "    X_train['x_IQR'] = pd.Series(x_list_train).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X_train['y_IQR'] = pd.Series(y_list_train).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X_train['z_IQR'] = pd.Series(z_list_train).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "\n",
    "    # negtive count\n",
    "    X_train['x_neg_count'] = pd.Series(x_list_train).apply(lambda x: np.sum(x < 0))\n",
    "    X_train['y_neg_count'] = pd.Series(y_list_train).apply(lambda x: np.sum(x < 0))\n",
    "    X_train['z_neg_count'] = pd.Series(z_list_train).apply(lambda x: np.sum(x < 0))\n",
    "\n",
    "    # positive count\n",
    "    X_train['x_pos_count'] = pd.Series(x_list_train).apply(lambda x: np.sum(x > 0))\n",
    "    X_train['y_pos_count'] = pd.Series(y_list_train).apply(lambda x: np.sum(x > 0))\n",
    "    X_train['z_pos_count'] = pd.Series(z_list_train).apply(lambda x: np.sum(x > 0))\n",
    "\n",
    "    # values above mean\n",
    "    X_train['x_above_mean'] = pd.Series(x_list_train).apply(lambda x: np.sum(x > x.mean()))\n",
    "    X_train['y_above_mean'] = pd.Series(y_list_train).apply(lambda x: np.sum(x > x.mean()))\n",
    "    X_train['z_above_mean'] = pd.Series(z_list_train).apply(lambda x: np.sum(x > x.mean()))\n",
    "\n",
    "    # number of peaks\n",
    "    X_train['x_peak_count'] = pd.Series(x_list_train).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X_train['y_peak_count'] = pd.Series(y_list_train).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X_train['z_peak_count'] = pd.Series(z_list_train).apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "\n",
    "\n",
    "    # energy\n",
    "    X_train['x_energy'] = pd.Series(x_list_train).apply(lambda x: np.sum(x**2)/window_size)\n",
    "    X_train['y_energy'] = pd.Series(y_list_train).apply(lambda x: np.sum(x**2)/window_size)\n",
    "    X_train['z_energy'] = pd.Series(z_list_train).apply(lambda x: np.sum(x**2)/window_size)\n",
    "\n",
    "    # avg resultant\n",
    "    X_train['avg_result_accl'] = [i.mean() for i in ((pd.Series(x_list_train)**2 + pd.Series(y_list_train)**2 + pd.Series(z_list_train)**2)**0.5)]\n",
    "\n",
    "    # signal magnitude area\n",
    "    X_train['sma'] =    pd.Series(x_list_train).apply(lambda x: np.sum(abs(x)/window_size)) + pd.Series(y_list_train).apply(lambda x: np.sum(abs(x)/window_size)) \\\n",
    "                    + pd.Series(z_list_train).apply(lambda x: np.sum(abs(x)/window_size))\n",
    "\n",
    "\n",
    "\n",
    "    ### X TEST\n",
    "    x_list_test = []\n",
    "    y_list_test = []\n",
    "    z_list_test = []\n",
    "    test_labels = []\n",
    "\n",
    "    # creating overlaping windows of size window-size\n",
    "    for i in range(0, df_test.shape[0] - window_size, step_size):\n",
    "        xs = df_test['ax'].values[i: i + window_size]\n",
    "        ys = df_test['ay'].values[i: i + window_size]\n",
    "        zs = df_test['az'].values[i: i + window_size]\n",
    "        label = stats.mode(df_test['Actividades'][i: i + window_size])[0][0]\n",
    "\n",
    "        x_list_test.append(xs)\n",
    "        y_list_test.append(ys)\n",
    "        z_list_test.append(zs)\n",
    "        test_labels.append(label)\n",
    "\n",
    "    # Statistical Features on raw x, y and z in time domain\n",
    "    X_test = pd.DataFrame()\n",
    "\n",
    "    # mean\n",
    "    X_test['x_mean'] = pd.Series(x_list_test).apply(lambda x: x.mean())\n",
    "    X_test['y_mean'] = pd.Series(y_list_test).apply(lambda x: x.mean())\n",
    "    X_test['z_mean'] = pd.Series(z_list_test).apply(lambda x: x.mean())\n",
    "\n",
    "    # std dev\n",
    "    X_test['x_std'] = pd.Series(x_list_test).apply(lambda x: x.std())\n",
    "    X_test['y_std'] = pd.Series(y_list_test).apply(lambda x: x.std())\n",
    "    X_test['z_std'] = pd.Series(z_list_test).apply(lambda x: x.std())\n",
    "\n",
    "    # avg absolute diff\n",
    "    X_test['x_aad'] = pd.Series(x_list_test).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X_test['y_aad'] = pd.Series(y_list_test).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X_test['z_aad'] = pd.Series(z_list_test).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "\n",
    "    # min\n",
    "    X_test['x_min'] = pd.Series(x_list_test).apply(lambda x: x.min())\n",
    "    X_test['y_min'] = pd.Series(y_list_test).apply(lambda x: x.min())\n",
    "    X_test['z_min'] = pd.Series(z_list_test).apply(lambda x: x.min())\n",
    "\n",
    "    # max\n",
    "    X_test['x_max'] = pd.Series(x_list_test).apply(lambda x: x.max())\n",
    "    X_test['y_max'] = pd.Series(y_list_test).apply(lambda x: x.max())\n",
    "    X_test['z_max'] = pd.Series(z_list_test).apply(lambda x: x.max())\n",
    "\n",
    "\n",
    "    # median\n",
    "    X_test['x_median'] = pd.Series(x_list_test).apply(lambda x: np.median(x))\n",
    "    X_test['y_median'] = pd.Series(y_list_test).apply(lambda x: np.median(x))\n",
    "    X_test['z_median'] = pd.Series(z_list_test).apply(lambda x: np.median(x))\n",
    "\n",
    "    # median abs dev \n",
    "    X_test['x_mad'] = pd.Series(x_list_test).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X_test['y_mad'] = pd.Series(y_list_test).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X_test['z_mad'] = pd.Series(z_list_test).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "\n",
    "    # interquartile range\n",
    "    X_test['x_IQR'] = pd.Series(x_list_test).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X_test['y_IQR'] = pd.Series(y_list_test).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X_test['z_IQR'] = pd.Series(z_list_test).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "\n",
    "    # negtive count\n",
    "    X_test['x_neg_count'] = pd.Series(x_list_test).apply(lambda x: np.sum(x < 0))\n",
    "    X_test['y_neg_count'] = pd.Series(y_list_test).apply(lambda x: np.sum(x < 0))\n",
    "    X_test['z_neg_count'] = pd.Series(z_list_test).apply(lambda x: np.sum(x < 0))\n",
    "\n",
    "    # positive count\n",
    "    X_test['x_pos_count'] = pd.Series(x_list_test).apply(lambda x: np.sum(x > 0))\n",
    "    X_test['y_pos_count'] = pd.Series(y_list_test).apply(lambda x: np.sum(x > 0))\n",
    "    X_test['z_pos_count'] = pd.Series(z_list_test).apply(lambda x: np.sum(x > 0))\n",
    "\n",
    "    # values above mean\n",
    "    X_test['x_above_mean'] = pd.Series(x_list_test).apply(lambda x: np.sum(x > x.mean()))\n",
    "    X_test['y_above_mean'] = pd.Series(y_list_test).apply(lambda x: np.sum(x > x.mean()))\n",
    "    X_test['z_above_mean'] = pd.Series(z_list_test).apply(lambda x: np.sum(x > x.mean()))\n",
    "\n",
    "    # number of peaks\n",
    "    X_test['x_peak_count'] = pd.Series(x_list_test).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X_test['y_peak_count'] = pd.Series(y_list_test).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X_test['z_peak_count'] = pd.Series(z_list_test).apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "    \n",
    "\n",
    "    # energy\n",
    "    X_test['x_energy'] = pd.Series(x_list_test).apply(lambda x: np.sum(x**2)/window_size)\n",
    "    X_test['y_energy'] = pd.Series(y_list_test).apply(lambda x: np.sum(x**2)/window_size)\n",
    "    X_test['z_energy'] = pd.Series(z_list_test).apply(lambda x: np.sum(x**2)/window_size)\n",
    "\n",
    "    # avg resultant\n",
    "    X_test['avg_result_accl'] = [i.mean() for i in ((pd.Series(x_list_test)**2 + pd.Series(y_list_test)**2 + pd.Series(z_list_test)**2)**0.5)]\n",
    "\n",
    "    # signal magnitude area\n",
    "    X_test['sma'] =    pd.Series(x_list_test).apply(lambda x: np.sum(abs(x)/window_size)) + pd.Series(y_list_test).apply(lambda x: np.sum(abs(x)/window_size)) \\\n",
    "                    + pd.Series(z_list_test).apply(lambda x: np.sum(abs(x)/window_size))\n",
    "\n",
    "    \n",
    "\n",
    "    act = np.array(train_labels)\n",
    "    act_test = np.array(test_labels)\n",
    "\n",
    "\n",
    "    ### Modelo regresión lineal\n",
    "    # standardization\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_data_lr = scaler.transform(X_train)\n",
    "    X_test_data_lr = scaler.transform(X_test)\n",
    "    lr = LogisticRegression(random_state = 21)\n",
    "    lr.fit(X_train_data_lr, act)\n",
    "    act_pred_lr = lr.predict(X_test_data_lr)\n",
    "    accuracyX = accuracy_score(act_test, act_pred_lr)\n",
    "    accuracyX_lr.append(accuracyX)\n",
    "\n",
    "\n",
    "    # Guarda valores de precisión, recall y fscore (un valor para cada actividad por ventana)\n",
    "    precision_recall_fscore_lr = precision_recall_fscore_support(act_test,act_pred_lr,average=None)\n",
    "    precisionX_lr.append(precision_recall_fscore_lr[0])\n",
    "    recallX_lr.append(precision_recall_fscore_lr[1])\n",
    "    fscoreX_lr.append(precision_recall_fscore_lr[2])\n",
    "    # Guarda valores de precisión, recall y fscore pesados (un valor para cada ventana)\n",
    "    precision_recall_fscore_lr_weighted = precision_recall_fscore_support(act_test,act_pred_lr,average='weighted')\n",
    "    precisionX_lr_W.append(precision_recall_fscore_lr_weighted[0])\n",
    "    recallX_lr_W.append(precision_recall_fscore_lr_weighted[1])\n",
    "    fscoreX_lr_W.append(precision_recall_fscore_lr_weighted[2])\n",
    "    \n",
    "    act = np.array(train_labels)\n",
    "    act_test = np.array(test_labels)\n",
    "\n",
    "    #Descomentar de acá al final si se quieren graficar las matrices de confusión para cada tamaño de ventana\n",
    "\n",
    "    # # Generar la matriz de confusión\n",
    "    # confusion_matrix_lf = confusion_matrix(act_test, act_pred_lr)\n",
    "\n",
    "    # # Crear figura y ejes\n",
    "    # fig, ax1 = plt.subplots()\n",
    "    # im = ax1.imshow(confusion_matrix_lf, cmap='YlGnBu')  # Cambiar el colormap aquí\n",
    "\n",
    "    # # Mostrar todas las etiquetas de las clases\n",
    "    # ax1.set_xticks(np.arange(len(labels)))\n",
    "    # ax1.set_yticks(np.arange(len(labels)))\n",
    "    # ax1.set_xticklabels(labels)\n",
    "    # ax1.set_yticklabels(labels)\n",
    "\n",
    "    # # Rotar las etiquetas para que sean legibles\n",
    "    # plt.setp(ax1.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # # Mostrar los valores de cada celda\n",
    "    # for i in range(len(labels)):\n",
    "    #     for j in range(len(labels)):\n",
    "    #         text=ax1.text(j, i, confusion_matrix_lf[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "    # # Configuración del título y etiquetas de los ejes\n",
    "    # plt.title(\"Confusion matrix Regresión lineal\")\n",
    "    # plt.xlabel('Predicted label')\n",
    "    # plt.ylabel('True label')\n",
    "\n",
    "    # # Agregar la barra de referencia al lado\n",
    "    # plt.colorbar(im, ax=ax1)\n",
    "\n",
    "    # # Eliminar las líneas divisorias entre los cuadrados\n",
    "    # plt.gca().spines['top'].set_visible(False)\n",
    "    # plt.gca().spines['right'].set_visible(False)\n",
    "    # plt.gca().spines['bottom'].set_visible(False)\n",
    "    # plt.gca().spines['left'].set_visible(False)\n",
    "    # plt.tick_params(axis=u'both', which=u'both',length=0)\n",
    "    # ax1.grid(False)\n",
    "    # plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # standardization\n",
    "    X_train_data_rf = scaler.transform(X_train)\n",
    "    X_test_data_rf = scaler.transform(X_test)\n",
    "    #Entrenar el modelo\n",
    "    rf = RandomForestClassifier(random_state=21)\n",
    "    rf.fit(X_train_data_rf, act)\n",
    "    act_pred_rf = rf.predict(X_test_data_rf)\n",
    "    accuracyX = accuracy_score(act_test, act_pred_rf)\n",
    "    accuracyX_rf.append(accuracyX)\n",
    "    # recallX= recall_score(act_test,act_pred_rf, average = None)\n",
    "    # recallX_rf.append(recallX)\n",
    "    precision_recall_fscore_rf = precision_recall_fscore_support(act_test,act_pred_rf,average=None)\n",
    "    precisionX_rf.append(precision_recall_fscore_rf[0])\n",
    "    recallX_rf.append(precision_recall_fscore_rf[1])\n",
    "    fscoreX_rf.append(precision_recall_fscore_rf[2])\n",
    "    precision_recall_fscore_rf_weighted = precision_recall_fscore_support(act_test,act_pred_rf,average='weighted')\n",
    "    precisionX_rf_W.append(precision_recall_fscore_rf_weighted[0])\n",
    "    recallX_rf_W.append(precision_recall_fscore_rf_weighted[1])\n",
    "    fscoreX_rf_W.append(precision_recall_fscore_rf_weighted[2])\n",
    "\n",
    "\n",
    "    #Descomentar de acá al final si se quieren graficar las matrices de confusión para cada tamaño de ventana\n",
    "\n",
    "    # # Generar la matriz de confusión\n",
    "    # confusion_matrix_rf = confusion_matrix(act_test, act_pred_rf)\n",
    "\n",
    "    # # Crear figura y ejes\n",
    "    # fig, ax2 = plt.subplots()\n",
    "    # im = ax2.imshow(confusion_matrix_rf, cmap='YlGnBu')  # Cambiar el colormap aquí\n",
    "\n",
    "    # # Mostrar todas las etiquetas de las clases\n",
    "    # ax2.set_xticks(np.arange(len(labels)))\n",
    "    # ax2.set_yticks(np.arange(len(labels)))\n",
    "    # ax2.set_xticklabels(labels)\n",
    "    # ax2.set_yticklabels(labels)\n",
    "\n",
    "    # # Rotar las etiquetas para que sean legibles\n",
    "    # plt.setp(ax2.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # # Mostrar los valores de cada celda\n",
    "    # for i in range(len(labels)):\n",
    "    #     for j in range(len(labels)):\n",
    "    #         text=ax2.text(j, i, confusion_matrix_rf[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "    # # Configuración del título y etiquetas de los ejes\n",
    "    # plt.title(\"Confusion matrix Random Forest\")\n",
    "    # plt.xlabel('Predicted label')\n",
    "    # plt.ylabel('True label')\n",
    "\n",
    "    # # Agregar la barra de referencia al lado\n",
    "    # plt.colorbar(im, ax=ax2)\n",
    "\n",
    "    # # Eliminar las líneas divisorias entre los cuadrados\n",
    "    # plt.gca().spines['top'].set_visible(False)\n",
    "    # plt.gca().spines['right'].set_visible(False)\n",
    "    # plt.gca().spines['bottom'].set_visible(False)\n",
    "    # plt.gca().spines['left'].set_visible(False)\n",
    "    # plt.tick_params(axis=u'both', which=u'both',length=0)\n",
    "    # ax2.grid(False)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "precision_caminando_rf = [array[0] for array in precisionX_rf]\n",
    "precision_quieta_rf = [array[1] for array in precisionX_rf]\n",
    "precision_come_rf = [array[2] for array in precisionX_rf]\n",
    "precision_caminando_lr = [array[0] for array in precisionX_lr]\n",
    "precision_quieta_lr = [array[1] for array in precisionX_lr]\n",
    "precision_come_lr = [array[2] for array in precisionX_lr]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, sharex=True, sharey=True)\n",
    "#axs.plot(windows, recallX_lr, label='Regresión lineal')\n",
    "ax1.plot(windows, precision_caminando_rf, label='Caminando', color='red')\n",
    "ax1.plot(windows, precision_quieta_rf, label='Quieta', color='blue')\n",
    "ax1.plot(windows, precision_come_rf, label='Comiendo', color='gray')\n",
    "\n",
    "\n",
    "ax1.set_ylabel('Precisión', fontsize=18)\n",
    "ax1.set_title('Random forest', fontsize=18)\n",
    "\n",
    "\n",
    "#axs.plot(windows, recallX_lr, label='Regresión lineal')\n",
    "ax2.plot(windows, precision_caminando_lr, color='red')\n",
    "ax2.plot(windows, precision_quieta_lr, color='blue')\n",
    "ax2.plot(windows, precision_come_lr, color='gray')\n",
    "\n",
    "\n",
    "ax2.set_xlabel('Tamaño de ventanas [N° de mediciones]', fontsize=18)\n",
    "ax2.set_ylabel('Precisión', fontsize=18)\n",
    "ax2.set_title('Regresión lineal',fontsize=18)\n",
    "ax1.tick_params(axis='x', labelsize=12)\n",
    "ax1.tick_params(axis='y', labelsize=12)\n",
    "ax2.tick_params(axis='x', labelsize=12)\n",
    "ax2.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "\n",
    "#Añade lineas verticales\n",
    "ylim1 = ax1.get_ylim()\n",
    "ylim2 = ax2.get_ylim()\n",
    "ax1.axvline(x=98, color='red', linestyle='--', linewidth=1)\n",
    "ax1.text(98, ylim1[0] - (ylim1[1] - ylim1[0]) * 0.1, '98', fontsize=12, color='red', ha='center')\n",
    "ax2.axvline(x=578, color='red', linestyle='--', linewidth=1)\n",
    "ax2.text(578, ylim2[0] - (ylim2[1] - ylim2[0]) * 0.1, '578', fontsize=12, color='red', ha='center')\n",
    "\n",
    "current_labels = plt.gca().get_xticks()\n",
    "new_labels = [label for label in current_labels if label != 600 and label!=1000 and label!=1200 and label!=-200]\n",
    "\n",
    "# Establecer las nuevas etiquetas del eje x\n",
    "plt.gca().set_xticks(new_labels)\n",
    "\n",
    "\n",
    "ax1.legend(loc=(0.6,0), fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "recall_caminando_rf = [array[0] for array in recallX_rf]\n",
    "recall_quieta_rf = [array[1] for array in recallX_rf]\n",
    "recall_come_rf = [array[2] for array in recallX_rf]\n",
    "recall_caminando_lr = [array[0] for array in recallX_lr]\n",
    "recall_quieta_lr = [array[1] for array in recallX_lr]\n",
    "recall_come_lr = [array[2] for array in recallX_lr]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, sharex=True, sharey=True)\n",
    "#axs.plot(windows, recallX_lr, label='Regresión lineal')\n",
    "ax1.plot(windows, recall_caminando_rf, label='Caminando', color='red')\n",
    "ax1.plot(windows, recall_quieta_rf, label='Quieta', color='blue')\n",
    "ax1.plot(windows, recall_come_rf, label='Comiendo', color='gray')\n",
    "\n",
    "\n",
    "ax1.set_ylabel('Recall', fontsize=18)\n",
    "ax1.set_title('Random forest', fontsize=18)\n",
    "\n",
    "\n",
    "#axs.plot(windows, recallX_lr, label='Regresión lineal')\n",
    "ax2.plot(windows, recall_caminando_lr, color='red')\n",
    "ax2.plot(windows, recall_quieta_lr, color='blue')\n",
    "ax2.plot(windows, recall_come_lr, color='gray')\n",
    "\n",
    "\n",
    "ax2.set_xlabel('Tamaño de ventanas [N° de mediciones]', fontsize=18)\n",
    "ax2.set_ylabel('Recall', fontsize=18)\n",
    "ax2.set_title('Regresión lineal',fontsize=18)\n",
    "ax1.tick_params(axis='x', labelsize=12)\n",
    "ax1.tick_params(axis='y', labelsize=12)\n",
    "ax2.tick_params(axis='x', labelsize=12)\n",
    "ax2.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "\n",
    "#Añade lineas verticales\n",
    "ylim1 = ax1.get_ylim()\n",
    "ylim2 = ax2.get_ylim()\n",
    "ax1.axvline(x=98, color='red', linestyle='--', linewidth=1)\n",
    "ax1.text(98, ylim1[0] - (ylim1[1] - ylim1[0]) * 0.1, '98', fontsize=12, color='red', ha='center')\n",
    "ax2.axvline(x=578, color='red', linestyle='--', linewidth=1)\n",
    "ax2.text(578, ylim2[0] - (ylim2[1] - ylim2[0]) * 0.1, '578', fontsize=12, color='red', ha='center')\n",
    "\n",
    "current_labels = plt.gca().get_xticks()\n",
    "new_labels = [label for label in current_labels if label != 600 and label!=1000 and label!=1200 and label!=-200]\n",
    "\n",
    "# Establecer las nuevas etiquetas del eje x\n",
    "plt.gca().set_xticks(new_labels)\n",
    "\n",
    "\n",
    "ax1.legend(loc=(0.6,0), fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fscore_caminando_rf = [array[0] for array in fscoreX_rf]\n",
    "fscore_quieta_rf = [array[1] for array in fscoreX_rf]\n",
    "fscore_come_rf = [array[2] for array in fscoreX_rf]\n",
    "fscore_caminando_lr = [array[0] for array in fscoreX_lr]\n",
    "fscore_quieta_lr = [array[1] for array in fscoreX_lr]\n",
    "fscore_come_lr = [array[2] for array in fscoreX_lr]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, sharex=True, sharey=True)\n",
    "#axs.plot(windows, recallX_lr, label='Regresión lineal')\n",
    "ax1.plot(windows, fscore_caminando_rf, label='Caminando', color='red')\n",
    "ax1.plot(windows, fscore_quieta_rf, label='Quieta', color='blue')\n",
    "ax1.plot(windows, fscore_come_rf, label='Comiendo', color='gray')\n",
    "\n",
    "\n",
    "ax1.set_ylabel('f$_1$-score', fontsize=18)\n",
    "ax1.set_title('Random forest', fontsize=18)\n",
    "\n",
    "\n",
    "#axs.plot(windows, recallX_lr, label='Regresión lineal')\n",
    "ax2.plot(windows, fscore_caminando_lr, color='red')\n",
    "ax2.plot(windows, fscore_quieta_lr, color='blue')\n",
    "ax2.plot(windows, fscore_come_lr, color='gray')\n",
    "\n",
    "\n",
    "ax2.set_xlabel('Tamaño de ventanas [N° de mediciones]', fontsize=18)\n",
    "ax2.set_ylabel('f$_1$-score', fontsize=18)\n",
    "ax2.set_title('Regresión lineal',fontsize=18)\n",
    "ax1.tick_params(axis='x', labelsize=12)\n",
    "ax1.tick_params(axis='y', labelsize=12)\n",
    "ax2.tick_params(axis='x', labelsize=12)\n",
    "ax2.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "\n",
    "#Añade lineas verticales\n",
    "ylim1 = ax1.get_ylim()\n",
    "ylim2 = ax2.get_ylim()\n",
    "ax1.axvline(x=98, color='red', linestyle='--', linewidth=1)\n",
    "ax1.text(98, ylim1[0] - (ylim1[1] - ylim1[0]) * 0.1, '98', fontsize=12, color='red', ha='center')\n",
    "ax2.axvline(x=578, color='red', linestyle='--', linewidth=1)\n",
    "ax2.text(578, ylim2[0] - (ylim2[1] - ylim2[0]) * 0.1, '578', fontsize=12, color='red', ha='center')\n",
    "\n",
    "current_labels = plt.gca().get_xticks()\n",
    "new_labels = [label for label in current_labels if label != 600 and label!=1000 and label!=1200 and label!=-200]\n",
    "\n",
    "# Establecer las nuevas etiquetas del eje x\n",
    "plt.gca().set_xticks(new_labels)\n",
    "\n",
    "\n",
    "ax1.legend(loc=(0.45,0), fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy vs tamaño ventanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, sharex=True, sharey=True)\n",
    "axs.plot(windows, accuracyX_lr, label='Regresión lineal')\n",
    "axs.plot(windows, accuracyX_rf, label='Random Forest')\n",
    "\n",
    "#Añade lineas verticales\n",
    "ylim = axs.get_ylim()\n",
    "axs.axvline(x=98, color='red', linestyle='--', linewidth=1)\n",
    "axs.text(98, ylim[0] - (ylim[1] - ylim[0]) * 0.05, '98', fontsize=12, color='red', ha='center')\n",
    "axs.axvline(x=578, color='red', linestyle='--', linewidth=1)\n",
    "axs.text(578, ylim[0] - (ylim[1] - ylim[0]) * 0.05, '578', fontsize=12, color='red', ha='center')\n",
    "\n",
    "current_labels = plt.gca().get_xticks()\n",
    "new_labels = [label for label in current_labels if label != 600 and label!=1000 and label!=1200 and label!=-200]\n",
    "# Establecer las nuevas etiquetas del eje x\n",
    "plt.gca().set_xticks(new_labels)\n",
    "\n",
    "axs.set_title('Accuracy de los modelos vs tamaño de ventana', fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Tamaño de ventanas [N° de mediciones]', fontsize=20)\n",
    "plt.ylabel('Accuracy', fontsize=20)\n",
    "plt.ylim(0.75,1)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
